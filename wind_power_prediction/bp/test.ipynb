{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46d45d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy import signal\n",
    "import pywt\n",
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# 设置随机种子以确保结果可重现\n",
    "np.random.seed(42)\n",
    "\n",
    "# 创建figure目录（如果不存在）\n",
    "os.makedirs('figure', exist_ok=True)\n",
    "\n",
    "# 加载训练和测试数据\n",
    "train_data = pd.read_excel('/data/jinming/ee_prediction/data/train.xlsx')\n",
    "test_data = pd.read_excel('/data/jinming/ee_prediction/data/test.xlsx')\n",
    "\n",
    "# 提取功率数据（第一列是实际功率 - 已归一化）\n",
    "train_power = train_data.iloc[:, 0].values\n",
    "test_power = test_data.iloc[:, 0].values\n",
    "\n",
    "# 数据已经归一化，无需再次归一化\n",
    "train_power_scaled = train_power\n",
    "test_power_scaled = test_power\n",
    "\n",
    "print(f\"训练数据形状: {train_power_scaled.shape}\")\n",
    "print(f\"测试数据形状: {test_power_scaled.shape}\")\n",
    "\n",
    "# CR指标计算函数\n",
    "def calculate_CR(PM, PP):\n",
    "    \"\"\"\n",
    "    计算CR指标（准确度指标）\n",
    "    \n",
    "    参数:\n",
    "    PM: 实际值数组\n",
    "    PP: 预测值数组\n",
    "    \n",
    "    返回:\n",
    "    CR: CR指标值（百分比）\n",
    "    \"\"\"\n",
    "    N = len(PM)\n",
    "    Ri = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        if PM[i] > 0.2:\n",
    "            Ri[i] = (PM[i] - PP[i]) / PM[i]\n",
    "        else:\n",
    "            Ri[i] = (PM[i] - PP[i]) / 0.2\n",
    "    \n",
    "    rms_error = np.sqrt(np.mean(Ri**2))\n",
    "    CR = (1 - rms_error) * 100\n",
    "    return CR\n",
    "\n",
    "# 准备训练数据：为3个不同预测时长创建数据集\n",
    "def create_dataset_for_horizon(data, input_size=96, predict_horizon=1, step=1):\n",
    "    \"\"\"\n",
    "    为特定预测时长创建训练数据集\n",
    "    \n",
    "    参数:\n",
    "    data: 时间序列数据\n",
    "    input_size: 输入窗口大小\n",
    "    predict_horizon: 预测时长（1=15分钟, 4=1小时, 16=4小时）\n",
    "    step: 滑动窗口步长\n",
    "    \n",
    "    返回:\n",
    "    X: 输入序列，形状 (样本数量, 输入长度)\n",
    "    y: 输出值，形状 (样本数量, 1)\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(0, len(data) - input_size - predict_horizon, step):\n",
    "        X.append(data[i:i+input_size])\n",
    "        y.append(data[i+input_size+predict_horizon-1])\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)\n",
    "\n",
    "# 分割训练和验证集\n",
    "def split_train_val(X, y, train_ratio=0.8):\n",
    "    train_size = int(len(X) * train_ratio)\n",
    "    X_train = X[:train_size]\n",
    "    y_train = y[:train_size]\n",
    "    X_val = X[train_size:]\n",
    "    y_val = y[train_size:]\n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n",
    "# 带早停机制的BP神经网络类\n",
    "class BPNeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size=1, learning_rate=0.01, use_adam=True):\n",
    "        \"\"\"\n",
    "        初始化BP神经网络\n",
    "        \n",
    "        参数:\n",
    "        input_size: 输入层节点数\n",
    "        hidden_size: 隐藏层节点数\n",
    "        output_size: 输出层节点数（默认为1）\n",
    "        learning_rate: 学习率\n",
    "        use_adam: 是否使用Adam优化器\n",
    "        \"\"\"\n",
    "        # 网络结构参数\n",
    "        self.input_size = input_size    # 输入层节点数\n",
    "        self.hidden_size = hidden_size  # 隐藏层节点数\n",
    "        self.output_size = output_size  # 输出层节点数\n",
    "        self.learning_rate = learning_rate  # 学习率\n",
    "        self.use_adam = use_adam  # 是否使用Adam优化器\n",
    "        \n",
    "        # 初始化网络权重和偏置\n",
    "        # Xavier初始化，用于更稳定的反向传播\n",
    "        self.W1 = np.random.randn(input_size, hidden_size) * np.sqrt(1/input_size)  # 输入层到隐藏层权重\n",
    "        self.b1 = np.zeros((1, hidden_size))  # 隐藏层偏置\n",
    "        self.W2 = np.random.randn(hidden_size, output_size) * np.sqrt(1/hidden_size)  # 隐藏层到输出层权重\n",
    "        self.b2 = np.zeros((1, output_size))  # 输出层偏置\n",
    "        \n",
    "        # Adam优化器参数\n",
    "        if use_adam:\n",
    "            # 动量参数\n",
    "            self.beta1 = 0.9\n",
    "            self.beta2 = 0.999\n",
    "            self.epsilon = 1e-8\n",
    "            \n",
    "            # 初始化梯度动量和平方梯度动量\n",
    "            self.m_W1 = np.zeros_like(self.W1)\n",
    "            self.m_b1 = np.zeros_like(self.b1)\n",
    "            self.m_W2 = np.zeros_like(self.W2)\n",
    "            self.m_b2 = np.zeros_like(self.b2)\n",
    "            \n",
    "            self.v_W1 = np.zeros_like(self.W1)\n",
    "            self.v_b1 = np.zeros_like(self.b1)\n",
    "            self.v_W2 = np.zeros_like(self.W2)\n",
    "            self.v_b2 = np.zeros_like(self.b2)\n",
    "            \n",
    "            # 时间步计数器\n",
    "            self.t = 0\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        \"\"\"\n",
    "        Sigmoid激活函数: f(x) = 1 / (1 + e^(-x))\n",
    "        将输入映射到(0,1)范围\n",
    "        \"\"\"\n",
    "        # 防止数值溢出\n",
    "        x = np.clip(x, -500, 500)\n",
    "        return 1.0 / (1.0 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_derivative(self, x):\n",
    "        \"\"\"\n",
    "        Sigmoid函数导数: f'(x) = f(x) * (1 - f(x))\n",
    "        用于反向传播梯度计算\n",
    "        \"\"\"\n",
    "        return x * (1.0 - x)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        前向传播算法\n",
    "        \n",
    "        参数:\n",
    "        X: 输入数据，形状 (样本数量, 输入维度)\n",
    "        \n",
    "        返回:\n",
    "        输出层输出\n",
    "        \"\"\"\n",
    "        # 第一层：输入层到隐藏层\n",
    "        self.z1 = np.dot(X, self.W1) + self.b1  # 隐藏层加权输入\n",
    "        self.a1 = self.sigmoid(self.z1)         # 隐藏层激活输出\n",
    "        \n",
    "        # 第二层：隐藏层到输出层\n",
    "        self.z2 = np.dot(self.a1, self.W2) + self.b2  # 输出层加权输入\n",
    "        self.a2 = self.sigmoid(self.z2)              # 输出层激活输出\n",
    "        \n",
    "        return self.a2\n",
    "    \n",
    "    def backward(self, X, y, output):\n",
    "        \"\"\"\n",
    "        反向传播算法\n",
    "        \n",
    "        参数:\n",
    "        X: 输入数据，形状 (样本数量, 输入维度)\n",
    "        y: 目标输出，形状 (样本数量, 输出维度)\n",
    "        output: 前向传播输出\n",
    "        \n",
    "        返回:\n",
    "        当前批次误差\n",
    "        \"\"\"\n",
    "        # 计算输出层误差\n",
    "        output_error = y - output  # 输出误差（目标值减去预测值）\n",
    "        output_delta = output_error * self.sigmoid_derivative(output)  # 输出层梯度\n",
    "        \n",
    "        # 计算隐藏层误差\n",
    "        hidden_error = np.dot(output_delta, self.W2.T)  # 通过链式法则计算隐藏层误差\n",
    "        hidden_delta = hidden_error * self.sigmoid_derivative(self.a1)  # 隐藏层梯度\n",
    "        \n",
    "        # 更新权重和偏置\n",
    "        m = X.shape[0]  # 样本数量\n",
    "        \n",
    "        # 计算梯度\n",
    "        dW2 = np.dot(self.a1.T, output_delta) / m\n",
    "        db2 = np.sum(output_delta, axis=0, keepdims=True) / m\n",
    "        dW1 = np.dot(X.T, hidden_delta) / m\n",
    "        db1 = np.sum(hidden_delta, axis=0, keepdims=True) / m\n",
    "        \n",
    "        if self.use_adam:\n",
    "            # Adam优化器更新\n",
    "            self.t += 1\n",
    "            \n",
    "            # 更新动量\n",
    "            self.m_W2 = self.beta1 * self.m_W2 + (1 - self.beta1) * dW2\n",
    "            self.m_b2 = self.beta1 * self.m_b2 + (1 - self.beta1) * db2\n",
    "            self.m_W1 = self.beta1 * self.m_W1 + (1 - self.beta1) * dW1\n",
    "            self.m_b1 = self.beta1 * self.m_b1 + (1 - self.beta1) * db1\n",
    "            \n",
    "            # 更新平方梯度动量\n",
    "            self.v_W2 = self.beta2 * self.v_W2 + (1 - self.beta2) * (dW2 ** 2)\n",
    "            self.v_b2 = self.beta2 * self.v_b2 + (1 - self.beta2) * (db2 ** 2)\n",
    "            self.v_W1 = self.beta2 * self.v_W1 + (1 - self.beta2) * (dW1 ** 2)\n",
    "            self.v_b1 = self.beta2 * self.v_b1 + (1 - self.beta2) * (db1 ** 2)\n",
    "            \n",
    "            # 偏置校正\n",
    "            m_W2_corrected = self.m_W2 / (1 - self.beta1 ** self.t)\n",
    "            m_b2_corrected = self.m_b2 / (1 - self.beta1 ** self.t)\n",
    "            m_W1_corrected = self.m_W1 / (1 - self.beta1 ** self.t)\n",
    "            m_b1_corrected = self.m_b1 / (1 - self.beta1 ** self.t)\n",
    "            \n",
    "            v_W2_corrected = self.v_W2 / (1 - self.beta2 ** self.t)\n",
    "            v_b2_corrected = self.v_b2 / (1 - self.beta2 ** self.t)\n",
    "            v_W1_corrected = self.v_W1 / (1 - self.beta2 ** self.t)\n",
    "            v_b1_corrected = self.v_b1 / (1 - self.beta2 ** self.t)\n",
    "            \n",
    "            # 使用Adam更新规则更新权重\n",
    "            self.W2 += self.learning_rate * m_W2_corrected / (np.sqrt(v_W2_corrected) + self.epsilon)\n",
    "            self.b2 += self.learning_rate * m_b2_corrected / (np.sqrt(v_b2_corrected) + self.epsilon)\n",
    "            self.W1 += self.learning_rate * m_W1_corrected / (np.sqrt(v_W1_corrected) + self.epsilon)\n",
    "            self.b1 += self.learning_rate * m_b1_corrected / (np.sqrt(v_b1_corrected) + self.epsilon)\n",
    "        else:\n",
    "            # 使用传统梯度下降更新权重\n",
    "            self.W2 += self.learning_rate * dW2\n",
    "            self.b2 += self.learning_rate * db2\n",
    "            self.W1 += self.learning_rate * dW1\n",
    "            self.b1 += self.learning_rate * db1\n",
    "        \n",
    "        # 计算总误差（均方误差）\n",
    "        total_error = np.mean(np.sum(np.square(output_error), axis=1))\n",
    "        return total_error\n",
    "    \n",
    "    def train(self, X_train, y_train, X_val=None, y_val=None, epochs=100, batch_size=32, \n",
    "              shuffle=False, verbose=True, early_stopping=True, patience=200, min_delta=1e-6):\n",
    "        \"\"\"\n",
    "        训练神经网络（带早停机制）\n",
    "        \n",
    "        参数:\n",
    "        X_train: 训练输入数据\n",
    "        y_train: 训练目标数据\n",
    "        X_val: 验证集输入数据（可选）\n",
    "        y_val: 验证集目标数据（可选）\n",
    "        epochs: 训练轮数\n",
    "        batch_size: 每次更新的批次大小\n",
    "        shuffle: 是否打乱数据\n",
    "        verbose: 是否打印训练进度\n",
    "        early_stopping: 是否启用早停机制\n",
    "        patience: 早停容忍轮数\n",
    "        min_delta: 最小改进阈值\n",
    "        \n",
    "        返回:\n",
    "        train_losses: 训练损失历史\n",
    "        val_losses: 验证损失历史\n",
    "        val_cr_scores: 验证CR指标历史\n",
    "        \"\"\"\n",
    "        train_losses = []  # 存储每轮训练损失\n",
    "        val_losses = []    # 存储每轮验证损失\n",
    "        val_cr_scores = [] # 存储每轮验证CR指标\n",
    "        n_samples = X_train.shape[0]  # 总样本数\n",
    "        \n",
    "        # 早停相关变量\n",
    "        best_cr_score = -np.inf  # 最佳CR指标（越高越好）\n",
    "        patience_counter = 0     # 耐心计数器\n",
    "        best_weights = None      # 最佳权重\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            if shuffle:\n",
    "                # 打乱数据以获得更稳定和鲁棒的训练\n",
    "                indices = np.random.permutation(n_samples)\n",
    "                X_shuffled = X_train[indices]\n",
    "                y_shuffled = y_train[indices]\n",
    "            else:\n",
    "                X_shuffled = X_train\n",
    "                y_shuffled = y_train\n",
    "            \n",
    "            epoch_loss = 0\n",
    "            # 小批量梯度下降，每次用batch_size个样本更新权重\n",
    "            for i in range(0, n_samples, batch_size):\n",
    "                end = min(i + batch_size, n_samples)\n",
    "                batch_X = X_shuffled[i:end]\n",
    "                batch_y = y_shuffled[i:end]\n",
    "                \n",
    "                # 前向传播\n",
    "                output = self.forward(batch_X)\n",
    "                \n",
    "                # 反向传播和权重更新\n",
    "                batch_loss = self.backward(batch_X, batch_y, output)\n",
    "                epoch_loss += batch_loss * (end - i) / n_samples\n",
    "            \n",
    "            train_losses.append(epoch_loss)\n",
    "            \n",
    "            # 在验证集上评估（如果提供）\n",
    "            if X_val is not None and y_val is not None:\n",
    "                val_output = self.forward(X_val)\n",
    "                val_loss = np.mean(np.sum(np.square(y_val - val_output), axis=1))\n",
    "                val_losses.append(val_loss)\n",
    "                \n",
    "                # 计算CR指标\n",
    "                val_predictions = val_output.flatten()\n",
    "                val_actual = y_val.flatten()\n",
    "                val_cr_score = calculate_CR(val_actual, val_predictions)\n",
    "                val_cr_scores.append(val_cr_score)\n",
    "                \n",
    "                # 早停检查\n",
    "                if early_stopping:\n",
    "                    if val_cr_score > best_cr_score + min_delta:\n",
    "                        best_cr_score = val_cr_score\n",
    "                        patience_counter = 0\n",
    "                        # 保存最佳权重\n",
    "                        best_weights = {\n",
    "                            'W1': self.W1.copy(),\n",
    "                            'b1': self.b1.copy(), \n",
    "                            'W2': self.W2.copy(),\n",
    "                            'b2': self.b2.copy()\n",
    "                        }\n",
    "                    else:\n",
    "                        patience_counter += 1\n",
    "                    \n",
    "                    # 如果超过耐心值，停止训练\n",
    "                    if patience_counter >= patience:\n",
    "                        if verbose:\n",
    "                            print(f\"\\n早停触发！在第 {epoch+1} 轮停止训练\")\n",
    "                            print(f\"最佳CR指标: {best_cr_score:.4f}%\")\n",
    "                        # 恢复最佳权重\n",
    "                        if best_weights:\n",
    "                            self.W1 = best_weights['W1']\n",
    "                            self.b1 = best_weights['b1']\n",
    "                            self.W2 = best_weights['W2']\n",
    "                            self.b2 = best_weights['b2']\n",
    "                        break\n",
    "                \n",
    "                # 打印训练进度\n",
    "                if verbose and (epoch % 200 == 0 or epoch == epochs - 1):\n",
    "                    print(f\"轮次 {epoch+1}/{epochs}, 训练损失: {epoch_loss:.6f}, 验证损失: {val_loss:.6f}, CR指标: {val_cr_score:.4f}%\")\n",
    "            else:\n",
    "                # 打印训练进度\n",
    "                if verbose and (epoch % 200 == 0 or epoch == epochs - 1):\n",
    "                    print(f\"轮次 {epoch+1}/{epochs}, 训练损失: {epoch_loss:.6f}\")\n",
    "        \n",
    "        return train_losses, val_losses if X_val is not None else train_losses, val_cr_scores if X_val is not None else []\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        预测函数\n",
    "        \n",
    "        参数:\n",
    "        X: 输入数据\n",
    "        \n",
    "        返回:\n",
    "        预测结果\n",
    "        \"\"\"\n",
    "        return self.forward(X)\n",
    "\n",
    "# 1. 自相关分析方法选择输入窗口大小\n",
    "def analyze_window_size_with_autocorrelation(data, max_lag=100):\n",
    "    \"\"\"\n",
    "    使用自相关和偏自相关分析确定合适的输入窗口大小\n",
    "    \n",
    "    参数:\n",
    "    data: 时间序列数据\n",
    "    max_lag: 最大滞后阶数\n",
    "    \n",
    "    返回:\n",
    "    suggested_window: 建议的输入窗口大小\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    \n",
    "    # 自相关分析\n",
    "    plt.subplot(211)\n",
    "    plot_acf(data, lags=max_lag, alpha=0.05, title='自相关函数 (ACF)')\n",
    "    \n",
    "    # 偏自相关分析\n",
    "    plt.subplot(212)\n",
    "    plot_pacf(data, lags=max_lag, alpha=0.05, method='ywm', title='偏自相关函数 (PACF)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('figure/acf_pacf_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 计算自相关系数\n",
    "    acf_values = sm.tsa.acf(data, nlags=max_lag, fft=True)\n",
    "    \n",
    "    # 找出自相关系数首次降到0.2以下的滞后阶数\n",
    "    for i, acf_val in enumerate(acf_values):\n",
    "        if i > 0 and abs(acf_val) < 0.2:\n",
    "            return i\n",
    "    \n",
    "    # 如果所有自相关系数都较高，建议使用最大滞后阶数的一半\n",
    "    return max(24, max_lag // 2)\n",
    "\n",
    "# 2. 简化的窗口大小选择方法\n",
    "def find_optimal_window_size_simple(data, window_sizes_to_test=[16, 24, 32, 48, 64, 96]):\n",
    "    \"\"\"\n",
    "    使用简单的训练验证集划分找到最优输入窗口大小\n",
    "    \n",
    "    参数:\n",
    "    data: 时间序列数据\n",
    "    window_sizes_to_test: 要测试的窗口大小列表\n",
    "    \n",
    "    返回:\n",
    "    best_window: 最优窗口大小\n",
    "    window_scores: 各窗口大小的性能评分\n",
    "    \"\"\"\n",
    "    best_window = 32  # 默认值\n",
    "    best_score = -np.inf\n",
    "    \n",
    "    # 分割数据为训练集和验证集（8:2）\n",
    "    train_size = int(len(data) * 0.8)\n",
    "    train_data = data[:train_size]\n",
    "    val_data = data[train_size:]\n",
    "    \n",
    "    window_scores = []\n",
    "    \n",
    "    print(\"开始测试不同窗口大小...\")\n",
    "    for window_size in window_sizes_to_test:\n",
    "        # 创建数据集\n",
    "        X_train, y_train = create_dataset_for_horizon(train_data, window_size, 1, 1)\n",
    "        X_val, y_val = create_dataset_for_horizon(val_data, window_size, 1, 1)\n",
    "        \n",
    "        if len(X_train) == 0 or len(X_val) == 0:\n",
    "            continue\n",
    "        \n",
    "        # 训练简化模型\n",
    "        model = BPNeuralNetwork(window_size, 32, 1, 0.01, use_adam=True)\n",
    "        model.train(X_train, y_train, epochs=300, batch_size=32, verbose=False)\n",
    "        \n",
    "        # 预测并计算CR指标\n",
    "        y_pred = model.predict(X_val)\n",
    "        cr_score = calculate_CR(y_val.flatten(), y_pred.flatten())\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        \n",
    "        window_scores.append((window_size, mse, cr_score))\n",
    "        print(f\"窗口大小 {window_size}: MSE = {mse:.6f}, CR = {cr_score:.2f}%\")\n",
    "        \n",
    "        if cr_score > best_score:\n",
    "            best_score = cr_score\n",
    "            best_window = window_size\n",
    "    \n",
    "    # 绘制窗口大小vs.性能指标曲线\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    plt.subplot(211)\n",
    "    plt.plot([w for w, m, c in window_scores], [m for w, m, c in window_scores], 'o-')\n",
    "    plt.xlabel('输入窗口大小')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.title('不同输入窗口大小的MSE对比')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(212)\n",
    "    plt.plot([w for w, m, c in window_scores], [c for w, m, c in window_scores], 'o-')\n",
    "    plt.axvline(x=best_window, color='r', linestyle='--', label=f'最佳窗口: {best_window}')\n",
    "    plt.xlabel('输入窗口大小')\n",
    "    plt.ylabel('CR指标 (%)')\n",
    "    plt.title('不同输入窗口大小的CR指标对比')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('figure/window_size_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return best_window, window_scores\n",
    "\n",
    "# 3. 添加时间特征\n",
    "def add_time_features(data, timestamps=None):\n",
    "    \"\"\"\n",
    "    为时间序列数据添加时间特征\n",
    "    \n",
    "    参数:\n",
    "    data: 时间序列数据\n",
    "    timestamps: 时间戳序列（如果没有提供，则假设等间隔采样，间隔15分钟）\n",
    "    \n",
    "    返回:\n",
    "    features: 添加时间特征后的数据\n",
    "    \"\"\"\n",
    "    n = len(data)\n",
    "    \n",
    "    # 如果没有提供时间戳，创建一个假设的时间序列（间隔15分钟）\n",
    "    if timestamps is None:\n",
    "        start_time = pd.Timestamp('2021-01-01')\n",
    "        timestamps = [start_time + pd.Timedelta(minutes=15*i) for i in range(n)]\n",
    "    \n",
    "    # 创建DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'power': data,\n",
    "        'timestamp': timestamps\n",
    "    })\n",
    "    \n",
    "    # 提取时间特征\n",
    "    df['hour'] = df['timestamp'].dt.hour\n",
    "    df['day'] = df['timestamp'].dt.day\n",
    "    df['month'] = df['timestamp'].dt.month\n",
    "    df['dayofweek'] = df['timestamp'].dt.dayofweek\n",
    "    df['dayofyear'] = df['timestamp'].dt.dayofyear\n",
    "    df['quarter'] = df['timestamp'].dt.quarter\n",
    "    \n",
    "    # 添加周期性特征（使用正弦和余弦变换）\n",
    "    # 小时周期性 (24小时周期)\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "    \n",
    "    # 一周内的天周期性 (7天周期)\n",
    "    df['day_of_week_sin'] = np.sin(2 * np.pi * df['dayofweek'] / 7)\n",
    "    df['day_of_week_cos'] = np.cos(2 * np.pi * df['dayofweek'] / 7)\n",
    "    \n",
    "    # 一年中的天周期性 (365天周期)\n",
    "    df['day_of_year_sin'] = np.sin(2 * np.pi * df['dayofyear'] / 365)\n",
    "    df['day_of_year_cos'] = np.cos(2 * np.pi * df['dayofyear'] / 365)\n",
    "    \n",
    "    # 将数据转换为numpy数组\n",
    "    feature_columns = ['power', 'hour_sin', 'hour_cos', 'day_of_week_sin', \n",
    "                      'day_of_week_cos', 'day_of_year_sin', 'day_of_year_cos']\n",
    "    features = df[feature_columns].values\n",
    "    \n",
    "    return features\n",
    "\n",
    "# 4. 差分处理\n",
    "def differencing(data, order=1):\n",
    "    \"\"\"\n",
    "    对时间序列进行差分处理\n",
    "    \n",
    "    参数:\n",
    "    data: 时间序列数据\n",
    "    order: 差分阶数\n",
    "    \n",
    "    返回:\n",
    "    diff_data: 差分后的数据\n",
    "    \"\"\"\n",
    "    diff_data = data.copy()\n",
    "    for _ in range(order):\n",
    "        diff_data = np.diff(diff_data, prepend=diff_data[0])\n",
    "    return diff_data\n",
    "\n",
    "# 5. 小波变换处理\n",
    "def wavelet_features(data, wavelet='db4', level=3):\n",
    "    \"\"\"\n",
    "    使用小波分解提取多尺度特征\n",
    "    \n",
    "    参数:\n",
    "    data: 时间序列数据\n",
    "    wavelet: 小波类型\n",
    "    level: 分解级别\n",
    "    \n",
    "    返回:\n",
    "    features: 小波特征\n",
    "    \"\"\"\n",
    "    # 确保数据长度是2的幂次方\n",
    "    n = len(data)\n",
    "    pad_size = int(2**np.ceil(np.log2(n))) - n\n",
    "    padded_data = np.pad(data, (0, pad_size), 'constant', constant_values=(0, 0))\n",
    "    \n",
    "    # 进行小波分解\n",
    "    coeffs = pywt.wavedec(padded_data, wavelet, level=level)\n",
    "    \n",
    "    # 使用小波系数作为特征\n",
    "    features = np.concatenate([coeffs[0]] + [c for c in coeffs[1:]], axis=0)[:n]\n",
    "    \n",
    "    return features.reshape(-1, 1)\n",
    "\n",
    "# 对训练数据进行自相关分析\n",
    "print(\"\\n开始使用自相关分析方法确定输入窗口大小...\")\n",
    "suggest_window_size = analyze_window_size_with_autocorrelation(train_power_scaled, max_lag=100)\n",
    "print(f\"自相关分析建议的输入窗口大小: {suggest_window_size}\")\n",
    "\n",
    "# 使用简化方法测试不同窗口大小\n",
    "print(\"\\n开始测试不同窗口大小的性能...\")\n",
    "window_sizes_to_test = [16, 24, 32, 48, 64, 96]\n",
    "best_window, window_scores = find_optimal_window_size_simple(train_power_scaled, window_sizes_to_test)\n",
    "print(f\"\\n最佳输入窗口大小: {best_window}\")\n",
    "\n",
    "# 最终确定的输入窗口大小\n",
    "final_input_size = best_window\n",
    "print(f\"\\n最终确定的输入窗口大小: {final_input_size}\")\n",
    "\n",
    "# 分析最终选择的窗口大小对应的自相关性\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_acf(train_power_scaled, lags=final_input_size, alpha=0.05, title=f'功率数据自相关函数 (滞后阶数 = {final_input_size})')\n",
    "plt.grid(True)\n",
    "plt.savefig('figure/final_window_acf.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 可视化时间序列数据的周期性特征\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# 绘制原始功率数据\n",
    "plt.subplot(311)\n",
    "plt.plot(train_power_scaled[:1000])\n",
    "plt.title('风电功率时间序列 (前1000个样本)')\n",
    "plt.ylabel('归一化功率')\n",
    "plt.grid(True)\n",
    "\n",
    "# 绘制功率数据的频谱\n",
    "plt.subplot(312)\n",
    "f, Pxx = signal.periodogram(train_power_scaled, fs=96)  # 假设每天96个样本点\n",
    "plt.semilogy(f[:len(f)//10], Pxx[:len(Pxx)//10])\n",
    "plt.title('功率数据频谱')\n",
    "plt.xlabel('频率 (周期/天)')\n",
    "plt.ylabel('功率谱密度')\n",
    "plt.grid(True)\n",
    "\n",
    "# 绘制差分后的数据\n",
    "plt.subplot(313)\n",
    "diff_data = differencing(train_power_scaled)\n",
    "plt.plot(diff_data[:1000])\n",
    "plt.title('一阶差分后的风电功率时间序列')\n",
    "plt.xlabel('时间点')\n",
    "plt.ylabel('差分值')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figure/time_series_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(\"\\n时间序列分析完成，结果已保存到figure文件夹\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
