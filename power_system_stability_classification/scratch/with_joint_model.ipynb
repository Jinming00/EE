{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e26a1269",
   "metadata": {},
   "source": [
    "# 电力系统稳定性分类模型\n",
    "\n",
    "相比于train.ipynb多了最后的 12. 动态权重集成模型 训练数据也分为了train_1.csv和train_2.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b059082e",
   "metadata": {},
   "source": [
    "## 1. 导入所需的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aabe23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, classification_report, \n",
    "                           roc_auc_score, roc_curve, precision_recall_curve, \n",
    "                           average_precision_score, f1_score)\n",
    "import catboost as cb\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "import time\n",
    "import warnings\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# 忽略警告\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dd0c93",
   "metadata": {},
   "source": [
    "## 2. 设置输出目录与全局参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7e1918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基础目录设置\n",
    "base_dir = '/data/jinming/ee_stable'\n",
    "\n",
    "\n",
    "\n",
    "# 创建最终结果比较和SHAP分析的目录\n",
    "comparison_dir = f'{base_dir}/comparison'\n",
    "shap_dir = f'{base_dir}/shap'\n",
    "os.makedirs(comparison_dir, exist_ok=True)\n",
    "os.makedirs(shap_dir, exist_ok=True)\n",
    "print(f\"创建了最终比较结果目录: {comparison_dir}\")\n",
    "print(f\"创建了SHAP分析目录: {shap_dir}\")\n",
    "\n",
    "\n",
    "\n",
    "# 设置统一的超参数优化trials数量和并行处理线程数\n",
    "n_trials_optuna = 100  # 可以根据计算资源和时间调整\n",
    "n_proc = 16          # 并行处理的线程数(CPU)\n",
    "print(f\"设置统一的Optuna超参数优化trials数量: {n_trials_optuna}\")\n",
    "print(f\"设置统一的并行处理线程数: {n_proc}\")\n",
    "\n",
    "# 创建各个模型的输出目录\n",
    "models = ['catboost', 'lightgbm', 'xgboost']\n",
    "for model in models:\n",
    "    model_dir = f'{base_dir}/{model}'\n",
    "    plots_dir = f'{model_dir}/plots'\n",
    "    models_dir = f'{model_dir}/models'\n",
    "    results_dir = f'{model_dir}/results'\n",
    "    \n",
    "    for directory in [plots_dir, models_dir, results_dir]:\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "        \n",
    "    print(f\"为 {model} 创建了输出目录\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2468825d",
   "metadata": {},
   "source": [
    "## 3. 数据加载与准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a50de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "print(\"===== 加载数据 =====\")\n",
    "train_df = pd.read_csv(f'{base_dir}/data/train_1.csv')\n",
    "test_df = pd.read_csv(f'{base_dir}/data/test.csv')\n",
    "val_df = pd.read_csv(f'{base_dir}/data/val.csv')\n",
    "\n",
    "# 数据准备\n",
    "print(\"===== 准备数据 =====\")\n",
    "# 排除不需要的列\n",
    "# drop_columns = ['stab', 'stabf_encoded', 'stabf', 'p1', 'p2', 'p3', 'p4']\n",
    "drop_columns = ['stab', 'stabf_encoded', 'stabf']\n",
    "\n",
    "X_train = train_df.drop(drop_columns, axis=1)\n",
    "X_test = test_df.drop(drop_columns, axis=1)\n",
    "X_val = val_df.drop(drop_columns, axis=1)\n",
    "\n",
    "y_train = train_df['stabf_encoded']\n",
    "y_test = test_df['stabf_encoded']\n",
    "y_val = val_df['stabf_encoded']\n",
    "\n",
    "print(f\"数据集维度 - 训练集: {X_train.shape}, 验证集: {X_val.shape}, 测试集: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9913eab",
   "metadata": {},
   "source": [
    "## 4. 特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203be401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(X_train, X_test, X_val):\n",
    "    \"\"\"为所有数据集创建特征\"\"\"\n",
    "    # 深拷贝，避免修改原始数据\n",
    "    X_train_new = X_train.copy()\n",
    "    X_test_new = X_test.copy()\n",
    "    X_val_new = X_val.copy()\n",
    "    \n",
    "    # 为所有数据集应用特征工程\n",
    "    for df in [X_train_new, X_test_new, X_val_new]:\n",
    "        # 基本交互特征\n",
    "        df['tau1_g1'] = df['tau1'] * df['g1']\n",
    "        df['tau2_g2'] = df['tau2'] * df['g2']\n",
    "        df['tau3_g3'] = df['tau3'] * df['g3']\n",
    "        df['tau4_g4'] = df['tau4'] * df['g4']\n",
    "        \n",
    "        # 延迟比率\n",
    "        df['tau_ratio'] = df[['tau1', 'tau2', 'tau3', 'tau4']].max(axis=1) / df[['tau1', 'tau2', 'tau3', 'tau4']].min(axis=1).replace(0, 0.001)\n",
    "        \n",
    "        # 延迟-弹性比率：每个节点的响应灵敏度\n",
    "        df['tau1_g1_ratio'] = df['tau1'] / df['g1'].replace(0, 0.001)\n",
    "        df['tau2_g2_ratio'] = df['tau2'] / df['g2'].replace(0, 0.001)\n",
    "        df['tau3_g3_ratio'] = df['tau3'] / df['g3'].replace(0, 0.001)\n",
    "        df['tau4_g4_ratio'] = df['tau4'] / df['g4'].replace(0, 0.001)\n",
    "        \n",
    "        # 系统总体弹性\n",
    "        df['total_elasticity'] = df['g1'] + df['g2'] + df['g3'] + df['g4']\n",
    "        \n",
    "        # 弹性分布的不均匀性\n",
    "        df['elasticity_disparity'] = df[['g1', 'g2', 'g3', 'g4']].max(axis=1) / df[['g1', 'g2', 'g3', 'g4']].min(axis=1).replace(0, 0.001)\n",
    "        \n",
    "        # 非线性特征 - 二次项\n",
    "        df['tau1_squared'] = df['tau1'] ** 2\n",
    "        df['tau2_squared'] = df['tau2'] ** 2\n",
    "        df['tau3_squared'] = df['tau3'] ** 2\n",
    "        df['tau4_squared'] = df['tau4'] ** 2\n",
    "        \n",
    "        # 节点间关系特征\n",
    "        df['tau_g_correlation'] = (\n",
    "            (df['tau1'] * df['g1']) + \n",
    "            (df['tau2'] * df['g2']) + \n",
    "            (df['tau3'] * df['g3']) + \n",
    "            (df['tau4'] * df['g4'])\n",
    "        ) / (df['tau1'] + df['tau2'] + df['tau3'] + df['tau4'] + 0.001)\n",
    "        \n",
    "        # 系统整体响应速度指标\n",
    "        df['system_response_speed'] = 4 / (\n",
    "            (1/df['tau1'].replace(0, 0.001)) + \n",
    "            (1/df['tau2'].replace(0, 0.001)) + \n",
    "            (1/df['tau3'].replace(0, 0.001)) + \n",
    "            (1/df['tau4'].replace(0, 0.001))\n",
    "        )\n",
    "    \n",
    "    return X_train_new, X_test_new, X_val_new\n",
    "\n",
    "# 应用特征工程\n",
    "print(\"\\n===== 执行特征工程 =====\")\n",
    "X_train_featured, X_test_featured, X_val_featured = create_features(X_train, X_test, X_val)\n",
    "print(f\"特征工程后特征数量: {X_train_featured.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085630ae",
   "metadata": {},
   "source": [
    "## 5. 特征选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f552d7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(X_train, X_test, X_val, y_train):\n",
    "    \"\"\"\n",
    "    基于相关性和重要性的特征自动选择\n",
    "    \"\"\"\n",
    "    print(\"\\n===== 开始自动特征选择 =====\")\n",
    "    \n",
    "    # 步骤1: 计算与目标变量的相关性\n",
    "    print(\"步骤1: 计算每个特征与目标的相关性\")\n",
    "    \n",
    "    # 特征与目标的相关性\n",
    "    feature_target_corr = {}\n",
    "    for col in X_train.columns:\n",
    "        # 使用点二列相关系数计算相关性\n",
    "        corr = abs(np.corrcoef(X_train[col], y_train)[0, 1])\n",
    "        feature_target_corr[col] = corr\n",
    "    \n",
    "    feature_corr_df = pd.DataFrame({\n",
    "        'Feature': list(feature_target_corr.keys()),\n",
    "        'Target_Correlation': list(feature_target_corr.values())\n",
    "    }).sort_values('Target_Correlation', ascending=False)\n",
    "    \n",
    "    # 可视化与目标的相关性\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.barplot(x='Target_Correlation', y='Feature', data=feature_corr_df.head(20))\n",
    "    plt.title('Feature Correlation with Target')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{base_dir}/catboost/plots/target_correlation.png')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"Top 10 与目标高相关的特征:\")\n",
    "    print(feature_corr_df.head(10))\n",
    "    \n",
    "    # 步骤2: 智能去除高相关特征，保留与目标相关性更高的特征\n",
    "    print(\"\\n步骤2: 智能去除冗余特征\")\n",
    "    \n",
    "    # 计算特征间相关性\n",
    "    corr_matrix = X_train.corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    \n",
    "    # 可视化相关性矩阵\n",
    "    plt.figure(figsize=(16, 14))\n",
    "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "    sns.heatmap(corr_matrix, cmap='coolwarm', center=0, mask=mask,\n",
    "                square=True, linewidths=.5, annot=False, fmt='.2f')\n",
    "    plt.title('Feature Correlation Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{base_dir}/catboost/plots/feature_correlation.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # 高度相关的特征对\n",
    "    correlation_threshold = 0.7\n",
    "    to_drop = set()\n",
    "    \n",
    "    for i, row_name in enumerate(upper.index):\n",
    "        for col_name in upper.columns[i:]:\n",
    "            if upper.loc[row_name, col_name] > correlation_threshold:\n",
    "                if feature_target_corr[row_name] > feature_target_corr[col_name]:\n",
    "                    to_drop.add(col_name)\n",
    "                else:\n",
    "                    to_drop.add(row_name)\n",
    "    \n",
    "    print(f\"移除 {len(to_drop)} 个高相关冗余特征:\")\n",
    "    print(\", \".join(list(to_drop)))\n",
    "    \n",
    "    # 移除冗余特征\n",
    "    X_train_filtered = X_train.drop(columns=list(to_drop))\n",
    "    X_test_filtered = X_test.drop(columns=list(to_drop))\n",
    "    X_val_filtered = X_val.drop(columns=list(to_drop))\n",
    "    \n",
    "    # 步骤3: 使用模型评估特征重要性\n",
    "    print(\"\\n步骤3: 基于模型特征重要性筛选\")\n",
    "    \n",
    "    # 训练一个LightGBM模型用于特征重要性评估\n",
    "    feature_selector = lgb.LGBMClassifier(\n",
    "        objective='binary',\n",
    "        metric='auc',\n",
    "        boosting_type='gbdt',\n",
    "        num_leaves=31,\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=100,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    feature_selector.fit(X_train_filtered, y_train)\n",
    "    \n",
    "    # 获取特征重要性\n",
    "    importances = feature_selector.feature_importances_\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': X_train_filtered.columns,\n",
    "        'Importance': importances\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    # 可视化特征重要性\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.barplot(x='Importance', y='Feature', data=feature_importance_df.head(20))\n",
    "    plt.title('LightGBM Feature Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{base_dir}/catboost/plots/feature_importance.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # 动态阈值设置\n",
    "    mean_importance = feature_importance_df['Importance'].mean()\n",
    "    importance_threshold = mean_importance * 0.5  # 使用平均值的50%作为阈值\n",
    "    print(f\"动态阈值: {importance_threshold:.2f} (平均重要性的50%)\")\n",
    "    selected_features = feature_importance_df[feature_importance_df['Importance'] > importance_threshold]['Feature'].tolist()\n",
    "    \n",
    "    # 如果筛选的特征太少，保留至少10个最重要的特征\n",
    "    if len(selected_features) < 10:\n",
    "        selected_features = feature_importance_df.head(10)['Feature'].tolist()\n",
    "    \n",
    "    print(f\"\\n最终选择了 {len(selected_features)}/{X_train.shape[1]} 个特征\")\n",
    "    print(f\"选择的特征: {', '.join(selected_features)}\")\n",
    "    \n",
    "    return X_train[selected_features], X_test[selected_features], X_val[selected_features], selected_features\n",
    "\n",
    "def select_features_manual(X_train, X_test, X_val):\n",
    "    \"\"\"手动选择指定的特征集\"\"\"\n",
    "    print(\"\\n===== 使用手动指定的特征 =====\")\n",
    "    \n",
    "   # 指定要保留的特征\n",
    "    selected_features = [\n",
    "        # 原始tau特征\n",
    "        'tau1', 'tau2', 'tau3', 'tau4',\n",
    "        \n",
    "        # 原始g特征\n",
    "        'g1', 'g2', 'g3', 'g4',\n",
    "        \n",
    "        # tau与g的交互项\n",
    "        'tau1_g1', 'tau2_g2', 'tau3_g3', 'tau4_g4',\n",
    "        \n",
    "        # tau的比率特征\n",
    "        'tau_ratio'\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "    # 验证所有指定的特征都存在\n",
    "    missing_features = [f for f in selected_features if f not in X_train.columns]\n",
    "    if missing_features:\n",
    "        print(f\"警告: 以下指定特征不存在: {', '.join(missing_features)}\")\n",
    "        # 过滤掉不存在的特征\n",
    "        selected_features = [f for f in selected_features if f in X_train.columns]\n",
    "    \n",
    "    print(f\"使用指定的 {len(selected_features)} 个特征:\")\n",
    "    print(f\"选择的特征: {', '.join(selected_features)}\")\n",
    "    \n",
    "    return X_train[selected_features], X_test[selected_features], X_val[selected_features], selected_features\n",
    "\n",
    "# 可以选择自动特征选择或手动特征选择\n",
    "\n",
    "# 使用自动特征选择: 根据feature_correlation 和 LightGBM 输出的 Feature Importance 来选择特征\n",
    "# X_train_final, X_test_final, X_val_final, selected_features = select_features(\n",
    "#     X_train_featured, X_test_featured, X_val_featured, y_train)\n",
    "\n",
    "# 使用手动特征选择：自己根据上面的特征工程和分析选择了几个觉得更好的特征\n",
    "X_train_final, X_test_final, X_val_final, selected_features = select_features_manual(\n",
    "   X_train_featured, X_test_featured, X_val_featured)\n",
    "\n",
    "print(f\"特征选择后特征数量: {X_train_final.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39290759",
   "metadata": {},
   "source": [
    "## 6. 模型训练和评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a59451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, y_train, X_val, y_val, X_test, y_test, model_name, is_xgb=False):\n",
    "    \"\"\"评估模型性能并生成可视化结果\"\"\"\n",
    "    # 准备评估报告的字典\n",
    "    results = {}\n",
    "    \n",
    "    # 如果是XGBoost模型，需要转换为DMatrix格式\n",
    "    if is_xgb:\n",
    "        dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "        dval = xgb.DMatrix(X_val, label=y_val)\n",
    "        dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "        \n",
    "        # 预测概率\n",
    "        y_val_prob = model.predict(dval)\n",
    "        y_test_prob = model.predict(dtest)\n",
    "        \n",
    "        # 预测类别\n",
    "        y_val_pred = (y_val_prob > 0.5).astype(int)\n",
    "        y_test_pred = (y_test_prob > 0.5).astype(int)\n",
    "    else:\n",
    "        # 预测概率\n",
    "        y_val_prob = model.predict_proba(X_val)[:, 1]\n",
    "        y_test_prob = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # 预测类别\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # 计算各种评估指标\n",
    "    val_auc = roc_auc_score(y_val, y_val_prob)\n",
    "    val_acc = accuracy_score(y_val, y_val_pred)\n",
    "    val_f1 = f1_score(y_val, y_val_pred)\n",
    "    val_f1_weighted = f1_score(y_val, y_val_pred, average='weighted')\n",
    "    \n",
    "    test_auc = roc_auc_score(y_test, y_test_prob)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    test_f1 = f1_score(y_test, y_test_pred)\n",
    "    test_f1_weighted = f1_score(y_test, y_test_pred, average='weighted')\n",
    "    \n",
    "    # 打印评估结果\n",
    "    print(f\"\\n===== {model_name} 在验证集上的性能 =====\")\n",
    "    print(f\"AUC: {val_auc:.4f}\")\n",
    "    print(f\"Weighted F1 Score: {val_f1_weighted:.4f}\")\n",
    "    print(f\"F1 Score: {val_f1:.4f}\")\n",
    "    print(f\"Accuracy: {val_acc:.4f}\")\n",
    "    \n",
    "    print(f\"\\n===== {model_name} 在测试集上的性能 =====\")\n",
    "    print(f\"AUC: {test_auc:.4f}\")\n",
    "    print(f\"Weighted F1 Score: {test_f1_weighted:.4f}\")\n",
    "    print(f\"F1 Score: {test_f1:.4f}\")\n",
    "    print(f\"Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    # 保存评估结果\n",
    "    results = {\n",
    "        'model_name': model_name,\n",
    "        'validation': {\n",
    "            'auc': val_auc,\n",
    "            'accuracy': val_acc,\n",
    "            'f1': val_f1,\n",
    "            'f1_weighted': val_f1_weighted\n",
    "        },\n",
    "        'test': {\n",
    "            'auc': test_auc,\n",
    "            'accuracy': test_acc,\n",
    "            'f1': test_f1,\n",
    "            'f1_weighted': test_f1_weighted\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # 创建模型的基本目录\n",
    "    model_dir = f'/data/jinming/ee_stable/{model_name.lower()}'\n",
    "    plots_dir = f'{model_dir}/plots'\n",
    "    results_dir = f'{model_dir}/results'\n",
    "    \n",
    "    # 绘制ROC曲线\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    # 验证集\n",
    "    fpr_val, tpr_val, _ = roc_curve(y_val, y_val_prob)\n",
    "    plt.plot(fpr_val, tpr_val, label=f'Validation Set (AUC = {val_auc:.4f})')\n",
    "    # 测试集\n",
    "    fpr_test, tpr_test, _ = roc_curve(y_test, y_test_prob)\n",
    "    plt.plot(fpr_test, tpr_test, label=f'Test Set (AUC = {test_auc:.4f})')\n",
    "    # 参考线\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - {model_name}')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{plots_dir}/{model_name.lower()}_roc_curves.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # 绘制PR曲线\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    # 验证集\n",
    "    prec_val, rec_val, _ = precision_recall_curve(y_val, y_val_prob)\n",
    "    avg_prec_val = average_precision_score(y_val, y_val_prob)\n",
    "    plt.plot(rec_val, prec_val, label=f'Validation Set (AP = {avg_prec_val:.4f})')\n",
    "    # 测试集\n",
    "    prec_test, rec_test, _ = precision_recall_curve(y_test, y_test_prob)\n",
    "    avg_prec_test = average_precision_score(y_test, y_test_prob)\n",
    "    plt.plot(rec_test, prec_test, label=f'Test Set (AP = {avg_prec_test:.4f})')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'PR Curve - {model_name}')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{plots_dir}/{model_name.lower()}_pr_curves.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # 保存性能结果\n",
    "    results_df = pd.DataFrame({\n",
    "        'Metric': ['AUC', 'Accuracy', 'F1 Score', 'Weighted F1 Score'],\n",
    "        'Validation Set': [val_auc, val_acc, val_f1, val_f1_weighted],\n",
    "        'Test Set': [test_auc, test_acc, test_f1, test_f1_weighted]\n",
    "    })\n",
    "    results_df.to_csv(f'{results_dir}/{model_name.lower()}_auc_performance.csv', index=False)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db83a8fb",
   "metadata": {},
   "source": [
    "## 7. 使用CatBoost训练模型 (AUC优化)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a59451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置CatBoost的输出目录\n",
    "plots_dir = '/data/jinming/ee_stable/catboost/plots'\n",
    "models_dir = '/data/jinming/ee_stable/catboost/models'\n",
    "results_dir = '/data/jinming/ee_stable/catboost/results'\n",
    "\n",
    "# 定义CatBoost的AUC优化目标函数\n",
    "def objective_catboost_auc(trial):\n",
    "    \"\"\"遍式Optuna优化目标函数 - 使用验证集上的AUC作为评价指标\"\"\"\n",
    "    # 定义CatBoost参数搜索空间\n",
    "    params = {\n",
    "        'loss_function': 'Logloss',  # 二分类问题\n",
    "        'eval_metric': 'AUC',\n",
    "        'verbose': 0,\n",
    "        \n",
    "        # 核心参数\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'iterations': 2000,          # 使用早停\n",
    "        'depth': trial.suggest_int('depth', 4, 10),\n",
    "        \n",
    "        # 正则化参数\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-8, 10.0, log=True),\n",
    "        'random_strength': trial.suggest_float('random_strength', 1e-8, 10.0, log=True),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0, 10.0),\n",
    "        \n",
    "        # 其他参数\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 100),\n",
    "        'leaf_estimation_iterations': trial.suggest_int('leaf_estimation_iterations', 1, 20),\n",
    "        'rsm': trial.suggest_float('rsm', 0.1, 1.0),  # 列采样比例\n",
    "        \n",
    "        # CPU特定参数\n",
    "        'task_type': 'CPU',\n",
    "        'thread_count': n_proc,  # 使用全局设置的线程数\n",
    "        \n",
    "        'random_seed': 42\n",
    "    }\n",
    "    \n",
    "    # 创建CatBoost模型\n",
    "    model = cb.CatBoostClassifier(**params)\n",
    "    \n",
    "    # 在训练集上训练模型，使用验证集进行早停\n",
    "    model.fit(\n",
    "        X_train_final, y_train,\n",
    "        eval_set=[(X_val_final, y_val)],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # 在验证集上预测\n",
    "    y_val_prob = model.predict_proba(X_val_final)[:, 1]\n",
    "    \n",
    "    # 计算AUC分数\n",
    "    auc_score = roc_auc_score(y_val, y_val_prob)\n",
    "    \n",
    "    # 打印当前试验的结果\n",
    "    print(f\"Trial {trial.number}: AUC = {auc_score:.4f}\")\n",
    "    \n",
    "    return auc_score\n",
    "\n",
    "# 创廟Optuna study对象 - 优化方向是最大化AUC\n",
    "print(\"\\n===== 开始CatBoost模型的Optuna调参过程 (AUC) =====\")\n",
    "catboost_study_auc = optuna.create_study(direction='maximize', study_name='catboost_auc_optimization')\n",
    "\n",
    "# 运行优化\n",
    "print(f\"开始运行 {n_trials_optuna} 次调参试验...\")\n",
    "start_time = time.time()\n",
    "catboost_study_auc.optimize(objective_catboost_auc, n_trials=n_trials_optuna)\n",
    "end_time = time.time()\n",
    "print(f\"调参完成! 耗时: {end_time - start_time:.2f}秒\")\n",
    "\n",
    "# 打印最佳参数和结果\n",
    "print(\"\\n===== 最佳参数 (AUC) =====\")\n",
    "print(f\"最佳AUC分数: {catboost_study_auc.best_value:.4f}\")\n",
    "print(\"最佳参数组合:\")\n",
    "for key, value in catboost_study_auc.best_params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "# 可视化调参过程\n",
    "plt.figure(figsize=(12, 8))\n",
    "optuna.visualization.matplotlib.plot_optimization_history(catboost_study_auc)\n",
    "plt.title('CatBoost Optimization History - AUC')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{plots_dir}/optuna_catboost_auc_history.png')\n",
    "plt.close()\n",
    "\n",
    "# 可视化超参数重要性\n",
    "plt.figure(figsize=(12, 8))\n",
    "optuna.visualization.matplotlib.plot_param_importances(catboost_study_auc)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{plots_dir}/optuna_catboost_auc_param_importances.png')\n",
    "plt.close()\n",
    "\n",
    "# 使用最佳参数训练最终模型\n",
    "print(\"\\n===== 使用最佳参数训练最终CatBoost模型 =====\")\n",
    "best_params_catboost = catboost_study_auc.best_params.copy()\n",
    "best_params_catboost['loss_function'] = 'Logloss'\n",
    "best_params_catboost['eval_metric'] = 'AUC'\n",
    "best_params_catboost['random_seed'] = 42\n",
    "best_params_catboost['task_type'] = 'CPU'\n",
    "best_params_catboost['thread_count'] = n_proc\n",
    "\n",
    "final_catboost_model = cb.CatBoostClassifier(**best_params_catboost)\n",
    "\n",
    "# 记录训练时间和迭代次数\n",
    "start_time = time.time()\n",
    "final_catboost_model.fit(\n",
    "    X_train_final, y_train,\n",
    "    eval_set=[(X_val_final, y_val)],\n",
    "    early_stopping_rounds=100,\n",
    "    verbose=50  # 每50次迭代显示一次\n",
    ")\n",
    "end_time = time.time()\n",
    "\n",
    "# 计算平均每迭代训练时间\n",
    "training_time = end_time - start_time\n",
    "actual_iterations = final_catboost_model.get_best_iteration() + 1  # +1因为迭代从0开始\n",
    "avg_time_per_iteration = training_time / actual_iterations\n",
    "\n",
    "print(f\"最终模型训练完成! 总耗时: {training_time:.2f}秒\")\n",
    "print(f\"实际迭代次数: {actual_iterations}\")\n",
    "print(f\"平均每迭代时间: {avg_time_per_iteration:.4f}秒\")\n",
    "\n",
    "# 保存训练时间指标\n",
    "catboost_time_metrics = {\n",
    "    'model': 'CatBoost',\n",
    "    'total_training_time': training_time,\n",
    "    'iterations': actual_iterations,\n",
    "    'avg_time_per_iteration': avg_time_per_iteration\n",
    "}\n",
    "\n",
    "# 保存最佳模型\n",
    "model_path = f'{models_dir}/catboost_auc.cbm'\n",
    "final_catboost_model.save_model(model_path)\n",
    "print(f\"\\n最佳模型已保存到: {model_path}\")\n",
    "\n",
    "# 保存所选特征列表\n",
    "with open(f'{models_dir}/catboost_selected_features.txt', 'w') as f:\n",
    "    f.write('\\n'.join(selected_features))\n",
    "print(f\"特征列表已保存到: {models_dir}/catboost_selected_features.txt\")\n",
    "\n",
    "# 使用评估函数评估模型\n",
    "catboost_results = evaluate_model(\n",
    "    final_catboost_model, \n",
    "    X_train_final, y_train, \n",
    "    X_val_final, y_val, \n",
    "    X_test_final, y_test,\n",
    "    \"CatBoost\"\n",
    ")\n",
    "\n",
    "# 将时间指标添加到结果中\n",
    "catboost_results['time_metrics'] = catboost_time_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa07a7d",
   "metadata": {},
   "source": [
    "## 8. 使用LightGBM训练模型 (AUC优化)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646420a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置LightGBM的输出目录\n",
    "plots_dir = '/data/jinming/ee_stable/lightgbm/plots'\n",
    "models_dir = '/data/jinming/ee_stable/lightgbm/models'\n",
    "results_dir = '/data/jinming/ee_stable/lightgbm/results'\n",
    "\n",
    "# 定义LightGBM的AUC优化目标函数\n",
    "def objective_lightgbm_auc(trial):\n",
    "    \"\"\"功Optuna优化目标函数 - 使用验证集上的AUC作为评价指标\"\"\"\n",
    "    # 定义LightGBM参数搜索空间\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'verbosity': -1,\n",
    "        \n",
    "        # 核心参数\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.5, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 30, 1000),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 10, 150),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "        \n",
    "        # 正则化参数\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "        \n",
    "        # 其他参数\n",
    "        'min_split_gain': trial.suggest_float('min_split_gain', 0, 0.5),\n",
    "        'min_child_weight': trial.suggest_float('min_child_weight', 1e-5, 10.0, log=True),\n",
    "        \n",
    "        # CPU并行参数\n",
    "        'n_jobs': n_proc,    # 使用全局设置的线程数\n",
    "\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    # 创建LightGBM模型\n",
    "    model = lgb.LGBMClassifier(**params)\n",
    "    \n",
    "    # 在训练集上训练模型，使用验证集进行早停\n",
    "    model.fit(\n",
    "        X_train_final, y_train,\n",
    "        eval_set=[(X_val_final, y_val)],\n",
    "        eval_metric='auc',\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)]\n",
    "    )\n",
    "    \n",
    "    # 在验证集上预测\n",
    "    y_val_prob = model.predict_proba(X_val_final)[:, 1]\n",
    "    \n",
    "    # 计算AUC分数\n",
    "    auc_score = roc_auc_score(y_val, y_val_prob)\n",
    "    \n",
    "    # 打印当前试验的结果\n",
    "    print(f\"Trial {trial.number}: AUC = {auc_score:.4f}\")\n",
    "    \n",
    "    return auc_score\n",
    "\n",
    "# 创建 Optuna study对象 - 优化方向是最大化AUC\n",
    "print(\"\\n===== 开始LightGBM模型的Optuna调参过程 (AUC) =====\")\n",
    "lightgbm_study_auc = optuna.create_study(direction='maximize', study_name='lightgbm_auc_optimization')\n",
    "\n",
    "# 运行优化\n",
    "print(f\"开始运行 {n_trials_optuna} 次调参试验...\")\n",
    "start_time = time.time()\n",
    "lightgbm_study_auc.optimize(objective_lightgbm_auc, n_trials=n_trials_optuna)\n",
    "end_time = time.time()\n",
    "print(f\"调参完成! 耗时: {end_time - start_time:.2f}秒\")\n",
    "\n",
    "# 打印最佳参数和结果\n",
    "print(\"\\n===== 最佳参数 (AUC) =====\")\n",
    "print(f\"最佳AUC分数: {lightgbm_study_auc.best_value:.4f}\")\n",
    "print(\"最佳参数组合:\")\n",
    "for key, value in lightgbm_study_auc.best_params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "# 可视化调参过程\n",
    "plt.figure(figsize=(12, 8))\n",
    "optuna.visualization.matplotlib.plot_optimization_history(lightgbm_study_auc)\n",
    "plt.title('LightGBM Optimization History - AUC')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{plots_dir}/optuna_lightgbm_auc_history.png')\n",
    "plt.close()\n",
    "\n",
    "# 可视化超参数重要性\n",
    "plt.figure(figsize=(12, 8))\n",
    "optuna.visualization.matplotlib.plot_param_importances(lightgbm_study_auc)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{plots_dir}/optuna_lightgbm_auc_param_importances.png')\n",
    "plt.close()\n",
    "\n",
    "# 使用最佳参数训练最终模型\n",
    "print(\"\\n===== 使用最佳参数训练最终LightGBM模型 =====\")\n",
    "best_params_lightgbm = lightgbm_study_auc.best_params.copy()\n",
    "best_params_lightgbm['objective'] = 'binary'\n",
    "best_params_lightgbm['metric'] = 'auc'\n",
    "best_params_lightgbm['boosting_type'] = 'gbdt'\n",
    "best_params_lightgbm['random_state'] = 42\n",
    "best_params_lightgbm['verbosity'] = -1\n",
    "best_params_lightgbm['n_jobs'] = n_proc\n",
    "\n",
    "final_lightgbm_model = lgb.LGBMClassifier(**best_params_lightgbm)\n",
    "\n",
    "# 记录训练时间和迭代次数\n",
    "start_time = time.time()\n",
    "eval_result = {}\n",
    "final_lightgbm_model.fit(\n",
    "    X_train_final, y_train,\n",
    "    eval_set=[(X_val_final, y_val)],\n",
    "    eval_metric='auc',\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=True),\n",
    "               lgb.record_evaluation(eval_result)]\n",
    ")\n",
    "end_time = time.time()\n",
    "\n",
    "# 计算平均每迭代训练时间\n",
    "training_time = end_time - start_time\n",
    "actual_iterations = final_lightgbm_model.best_iteration_ + 1  # +1因为从LightGBM的文档来看，迭代从1开始\n",
    "avg_time_per_iteration = training_time / actual_iterations\n",
    "\n",
    "print(f\"最终模型训练完成! 总耗时: {training_time:.2f}秒\")\n",
    "print(f\"实际迭代次数: {actual_iterations}\")\n",
    "print(f\"平均每迭代时间: {avg_time_per_iteration:.4f}秒\")\n",
    "\n",
    "# 保存训练时间指标\n",
    "lightgbm_time_metrics = {\n",
    "    'model': 'LightGBM',\n",
    "    'total_training_time': training_time,\n",
    "    'iterations': actual_iterations,\n",
    "    'avg_time_per_iteration': avg_time_per_iteration\n",
    "}\n",
    "\n",
    "# 保存最佳模型\n",
    "model_path = f'{models_dir}/lightgbm_auc.pkl'\n",
    "joblib.dump(final_lightgbm_model, model_path)\n",
    "print(f\"\\n最佳模型已保存到: {model_path}\")\n",
    "\n",
    "# 保存所选特征列表\n",
    "with open(f'{models_dir}/lightgbm_selected_features.txt', 'w') as f:\n",
    "    f.write('\\n'.join(selected_features))\n",
    "print(f\"特征列表已保存到: {models_dir}/lightgbm_selected_features.txt\")\n",
    "\n",
    "# 使用评估函数评估模型\n",
    "lightgbm_results = evaluate_model(\n",
    "    final_lightgbm_model, \n",
    "    X_train_final, y_train, \n",
    "    X_val_final, y_val, \n",
    "    X_test_final, y_test,\n",
    "    \"LightGBM\"\n",
    ")\n",
    "\n",
    "# 将时间指标添加到结果中\n",
    "lightgbm_results['time_metrics'] = lightgbm_time_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141bdfd5",
   "metadata": {},
   "source": [
    "## 9. 使用XGBoost训练模型 (AUC优化)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c583eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置XGBoost的输出目录\n",
    "plots_dir = '/data/jinming/ee_stable/xgboost/plots'\n",
    "models_dir = '/data/jinming/ee_stable/xgboost/models'\n",
    "results_dir = '/data/jinming/ee_stable/xgboost/results'\n",
    "\n",
    "# 定义XGBoost的AUC优化目标函数\n",
    "def objective_xgboost_auc(trial):\n",
    "    \"\"\"功Optuna优化目标函数 - 使用验证集上的AUC作为评价指标\"\"\"\n",
    "    # 定义XGBoost参数搜索空间\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'auc',\n",
    "        'verbosity': 0,\n",
    "        \n",
    "        # 核心参数\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.5, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        \n",
    "        # 正则化参数\n",
    "        'min_child_weight': trial.suggest_float('min_child_weight', 1, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 10),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-8, 10.0, log=True),\n",
    "        'lambda': trial.suggest_float('lambda', 1e-8, 10.0, log=True),\n",
    "        \n",
    "        # CPU特定参数\n",
    "        'tree_method': 'hist',  # 使用直方图算法\n",
    "        'n_jobs': n_proc,        # 使用全局设置的线程数\n",
    "        \n",
    "        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 0.1, 10.0),\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    # 准备数据\n",
    "    dtrain = xgb.DMatrix(X_train_final, label=y_train)\n",
    "    dval = xgb.DMatrix(X_val_final, label=y_val)\n",
    "    \n",
    "    # 设置评估集\n",
    "    evals = [(dtrain, 'train'), (dval, 'val')]\n",
    "    evals_result = {}\n",
    "    \n",
    "    # 训练模型，使用早停\n",
    "    model = xgb.train(\n",
    "        params=params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=2000,  # 最大迭代次数\n",
    "        evals=evals,\n",
    "        early_stopping_rounds=50,\n",
    "        evals_result=evals_result,\n",
    "        verbose_eval=False  # 只在每400次迭代时输出\n",
    "    )\n",
    "    \n",
    "    # 在验证集上预测概率\n",
    "    y_val_prob = model.predict(dval)\n",
    "    \n",
    "    # 计算AUC分数\n",
    "    auc_score = roc_auc_score(y_val, y_val_prob)\n",
    "    \n",
    "    # 打印当前试验的结果\n",
    "    print(f\"Trial {trial.number}: AUC = {auc_score:.4f}\")\n",
    "    \n",
    "    return auc_score\n",
    "\n",
    "# 创建 Optuna study对象 - 优化方向是最大化AUC\n",
    "print(\"\\n===== 开始XGBoost模型的Optuna调参过程 (AUC) =====\")\n",
    "xgboost_study_auc = optuna.create_study(direction='maximize', study_name='xgboost_auc_optimization')\n",
    "\n",
    "# 运行优化\n",
    "print(f\"开始运行 {n_trials_optuna} 次调参试验...\")\n",
    "start_time = time.time()\n",
    "xgboost_study_auc.optimize(objective_xgboost_auc, n_trials=n_trials_optuna)\n",
    "end_time = time.time()\n",
    "print(f\"调参完成! 耗时: {end_time - start_time:.2f}秒\")\n",
    "\n",
    "# 打印最佳参数和结果\n",
    "print(\"\\n===== 最佳参数 (AUC) =====\")\n",
    "print(f\"最佳AUC分数: {xgboost_study_auc.best_value:.4f}\")\n",
    "print(\"最佳参数组合:\")\n",
    "for key, value in xgboost_study_auc.best_params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "# 可视化调参过程\n",
    "plt.figure(figsize=(12, 8))\n",
    "optuna.visualization.matplotlib.plot_optimization_history(xgboost_study_auc)\n",
    "plt.title('XGBoost Optimization History - AUC')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{plots_dir}/optuna_xgboost_auc_history.png')\n",
    "plt.close()\n",
    "\n",
    "# 可视化超参数重要性\n",
    "plt.figure(figsize=(12, 8))\n",
    "optuna.visualization.matplotlib.plot_param_importances(xgboost_study_auc)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{plots_dir}/optuna_xgboost_auc_param_importances.png')\n",
    "plt.close()\n",
    "\n",
    "# 使用最佳参数训练最终模型\n",
    "print(\"\\n===== 使用最佳参数训练最终XGBoost模型 =====\")\n",
    "best_params_xgboost = xgboost_study_auc.best_params.copy()\n",
    "best_params_xgboost['objective'] = 'binary:logistic'\n",
    "best_params_xgboost['eval_metric'] = 'auc'\n",
    "best_params_xgboost['tree_method'] = 'hist'\n",
    "best_params_xgboost['n_jobs'] = n_proc\n",
    "best_params_xgboost['verbosity'] = 1\n",
    "best_params_xgboost['random_state'] = 42\n",
    "\n",
    "# 准备数据\n",
    "dtrain = xgb.DMatrix(X_train_final, label=y_train)\n",
    "dval = xgb.DMatrix(X_val_final, label=y_val)\n",
    "dtest = xgb.DMatrix(X_test_final, label=y_test)\n",
    "\n",
    "# 设置评估集\n",
    "evals = [(dtrain, 'train'), (dval, 'val')]\n",
    "evals_result = {}\n",
    "\n",
    "# 开始训练计时\n",
    "start_time = time.time()\n",
    "\n",
    "# 训练最终模型\n",
    "final_xgboost_model = xgb.train(\n",
    "    params=best_params_xgboost,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=3000,  # 设置足够大的最大迭代次数\n",
    "    evals=evals,\n",
    "    early_stopping_rounds=50,\n",
    "    evals_result=evals_result,\n",
    "    verbose_eval=50  # 每50轮显示一次进度\n",
    ")\n",
    "\n",
    "# 结束训练计时\n",
    "end_time = time.time()\n",
    "\n",
    "# 计算平均每迭代训练时间\n",
    "training_time = end_time - start_time\n",
    "actual_iterations = final_xgboost_model.best_iteration + 1  # +1因为迭代从0开始\n",
    "avg_time_per_iteration = training_time / actual_iterations\n",
    "\n",
    "print(f\"最终模型训练完成! 总耗时: {training_time:.2f}秒\")\n",
    "print(f\"实际迭代次数: {actual_iterations}\")\n",
    "print(f\"平均每迭代时间: {avg_time_per_iteration:.4f}秒\")\n",
    "\n",
    "# 保存训练时间指标\n",
    "xgboost_time_metrics = {\n",
    "    'model': 'XGBoost',\n",
    "    'total_training_time': training_time,\n",
    "    'iterations': actual_iterations,\n",
    "    'avg_time_per_iteration': avg_time_per_iteration\n",
    "}\n",
    "\n",
    "# 保存最佳模型\n",
    "model_path = f'{models_dir}/xgboost_auc.pkl'\n",
    "joblib.dump(final_xgboost_model, model_path)\n",
    "print(f\"\\n最佳模型已保存到: {model_path}\")\n",
    "\n",
    "# 保存所选特征列表\n",
    "with open(f'{models_dir}/xgboost_selected_features.txt', 'w') as f:\n",
    "    f.write('\\n'.join(selected_features))\n",
    "print(f\"特征列表已保存到: {models_dir}/xgboost_selected_features.txt\")\n",
    "\n",
    "# 使用评估函数评估模型\n",
    "xgboost_results = evaluate_model(\n",
    "    final_xgboost_model, \n",
    "    X_train_final, y_train, \n",
    "    X_val_final, y_val, \n",
    "    X_test_final, y_test,\n",
    "    \"XGBoost\",\n",
    "    is_xgb=True\n",
    ")\n",
    "\n",
    "# 将时间指标添加到结果中\n",
    "xgboost_results['time_metrics'] = xgboost_time_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11bfbdc",
   "metadata": {},
   "source": [
    "## 10. 模型性能比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ca1228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建模型性能比较表\n",
    "def compare_models(results_list):\n",
    "    \"\"\"比较多个模型的性能\"\"\"\n",
    "    # 提取验证集和测试集的指标\n",
    "    val_metrics = []\n",
    "    test_metrics = []\n",
    "    time_metrics = []\n",
    "    model_names = []\n",
    "    \n",
    "    for result in results_list:\n",
    "        model_names.append(result['model_name'])\n",
    "        val_metrics.append(result['validation'])\n",
    "        test_metrics.append(result['test'])\n",
    "        time_metrics.append(result['time_metrics'])\n",
    "    \n",
    "    # 创建验证集性能比较表\n",
    "    val_comparison = pd.DataFrame({\n",
    "        'Model': model_names,\n",
    "        'AUC': [metrics['auc'] for metrics in val_metrics],\n",
    "        'Accuracy': [metrics['accuracy'] for metrics in val_metrics],\n",
    "        'F1 Score': [metrics['f1'] for metrics in val_metrics],\n",
    "        'Weighted F1': [metrics['f1_weighted'] for metrics in val_metrics]\n",
    "    })\n",
    "    \n",
    "    # 创建测试集性能比较表\n",
    "    test_comparison = pd.DataFrame({\n",
    "        'Model': model_names,\n",
    "        'AUC': [metrics['auc'] for metrics in test_metrics],\n",
    "        'Accuracy': [metrics['accuracy'] for metrics in test_metrics],\n",
    "        'F1 Score': [metrics['f1'] for metrics in test_metrics],\n",
    "        'Weighted F1': [metrics['f1_weighted'] for metrics in test_metrics]\n",
    "    })\n",
    "    \n",
    "    # 创建时间性能比较表\n",
    "    time_comparison = pd.DataFrame({\n",
    "        'Model': model_names,\n",
    "        'Total Training Time (s)': [metrics['total_training_time'] for metrics in time_metrics],\n",
    "        'Iterations': [metrics['iterations'] for metrics in time_metrics],\n",
    "        'Avg Time Per Iteration (s)': [metrics['avg_time_per_iteration'] for metrics in time_metrics]\n",
    "    })\n",
    "    \n",
    "    return val_comparison, test_comparison, time_comparison\n",
    "\n",
    "# 整合所有模型的结果\n",
    "all_results = [catboost_results, lightgbm_results, xgboost_results]\n",
    "\n",
    "# 生成比较表\n",
    "val_comparison, test_comparison, time_comparison = compare_models(all_results)\n",
    "\n",
    "print(\"\\n===== 验证集上的模型性能比较 =====\")\n",
    "print(val_comparison)\n",
    "\n",
    "print(\"\\n===== 测试集上的模型性能比较 =====\")\n",
    "print(test_comparison)\n",
    "\n",
    "print(\"\\n===== 模型训练时间性能比较 =====\")\n",
    "print(time_comparison)\n",
    "\n",
    "\n",
    "# 使用比较目录保存比较结果\n",
    "print(f\"\\n保存比较结果到: {comparison_dir}\")\n",
    "\n",
    "# 保存比较结果到比较目录\n",
    "val_comparison.to_csv(f'{comparison_dir}/validation_comparison.csv', index=False)\n",
    "test_comparison.to_csv(f'{comparison_dir}/test_comparison.csv', index=False)\n",
    "time_comparison.to_csv(f'{comparison_dir}/time_performance_comparison.csv', index=False)\n",
    "print(f\"比较结果已保存到: {comparison_dir}\")\n",
    "\n",
    "# 可视化比较结果\n",
    "# 验证集AUC比较\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(val_comparison['Model'], val_comparison['AUC'])\n",
    "plt.title('Validation Set - AUC Comparison')\n",
    "plt.ylabel('AUC Score')\n",
    "plt.ylim(0.9, 1.0)  # 调整Y轴范围使差异更明显\n",
    "for i, v in enumerate(val_comparison['AUC']):\n",
    "    plt.text(i, v + 0.005, f\"{v:.4f}\", ha='center')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{comparison_dir}/validation_auc_comparison.png')\n",
    "plt.close()\n",
    "\n",
    "# 测试集AUC比较\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(test_comparison['Model'], test_comparison['AUC'])\n",
    "plt.title('Test Set - AUC Comparison')\n",
    "plt.ylabel('AUC Score')\n",
    "plt.ylim(0.9, 1.0)  # 调整Y轴范围使差异更明显\n",
    "for i, v in enumerate(test_comparison['AUC']):\n",
    "    plt.text(i, v + 0.005, f\"{v:.4f}\", ha='center')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{comparison_dir}/test_auc_comparison.png')\n",
    "plt.close()\n",
    "\n",
    "# 训练时间比较\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(time_comparison['Model'], time_comparison['Avg Time Per Iteration (s)'])\n",
    "plt.title('Average Time Per Iteration Comparison')\n",
    "plt.ylabel('Time (seconds)')\n",
    "for i, v in enumerate(time_comparison['Avg Time Per Iteration (s)']):\n",
    "    plt.text(i, v + 0.005, f\"{v:.4f}s\", ha='center')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{comparison_dir}/avg_time_per_iteration_comparison.png')\n",
    "plt.close()\n",
    "\n",
    "# 创建综合性能指标的雷达图\n",
    "def plot_radar_chart(data, save_path, title):\n",
    "    # 准备雷达图数据\n",
    "    metrics = ['AUC', 'Accuracy', 'F1 Score', 'Weighted F1']\n",
    "    models = data['Model']\n",
    "    \n",
    "    # 计算角度\n",
    "    N = len(metrics)\n",
    "    angles = np.linspace(0, 2*np.pi, N, endpoint=False).tolist()\n",
    "    angles += angles[:1]  # 闭合图形\n",
    "    \n",
    "    # 创建图形\n",
    "    fig, ax = plt.subplots(figsize=(10, 8), subplot_kw=dict(polar=True))\n",
    "    \n",
    "    # 为每个模型添加数据\n",
    "    for i, model in enumerate(models):\n",
    "        values = data.loc[i, metrics].values.flatten().tolist()\n",
    "        values += values[:1]  # 闭合图形\n",
    "        ax.plot(angles, values, linewidth=2, label=model)\n",
    "        ax.fill(angles, values, alpha=0.1)\n",
    "    \n",
    "    # 设置雷达图的刻度标签\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(metrics)\n",
    "    \n",
    "    # 设置Y轴范围\n",
    "    ax.set_ylim(0.8, 1.0)\n",
    "    \n",
    "    # 添加标题和图例\n",
    "    plt.title(title, size=15, pad=20)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 保存图形\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "# 绘制雷达图\n",
    "plot_radar_chart(val_comparison, f'{comparison_dir}/validation_radar_comparison.png', 'Validation Set - Model Performance Comparison')\n",
    "plot_radar_chart(test_comparison, f'{comparison_dir}/test_radar_comparison.png', 'Test Set - Model Performance Comparison')\n",
    "\n",
    "print(\"\\n===== 模型比较可视化已保存到结果目录 =====\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8893707b",
   "metadata": {},
   "source": [
    "## 11. SHAP值分析 - 特征重要性解释"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccb59ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入SHAP库\n",
    "import shap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"\\n===== 使用SHAP进行模型解释 =====\")\n",
    "\n",
    "# 从每个数据集中随机采样一部分数据用于SHAP分析(计算量很大)\n",
    "shap_sample_size = min(500, X_train_final.shape[0])  # 最多使用500个样本\n",
    "np.random.seed(42)  # 设置随机种子确保可重复性\n",
    "shap_indices = np.random.choice(X_train_final.shape[0], shap_sample_size, replace=False)\n",
    "X_shap = X_train_final.iloc[shap_indices]\n",
    "\n",
    "# 分析各个模型的SHAP值\n",
    "models_to_analyze = [\n",
    "    {\"name\": \"CatBoost\", \"model\": final_catboost_model, \"is_tree\": True},\n",
    "    {\"name\": \"LightGBM\", \"model\": final_lightgbm_model, \"is_tree\": True},\n",
    "    {\"name\": \"XGBoost\", \"model\": final_xgboost_model, \"is_tree\": True, \"is_xgb\": True}\n",
    "]\n",
    "\n",
    "for model_info in models_to_analyze:\n",
    "    model_name = model_info[\"name\"]\n",
    "    model = model_info[\"model\"]\n",
    "    is_tree = model_info[\"is_tree\"]\n",
    "    is_xgb = model_info.get(\"is_xgb\", False)\n",
    "    \n",
    "    # 创建模型特定的SHAP结果目录\n",
    "    model_shap_dir = f'{shap_dir}/{model_name.lower()}'\n",
    "    os.makedirs(model_shap_dir, exist_ok=True)\n",
    "    print(f\"\\n分析 {model_name} 模型 - 保存结果到 {model_shap_dir}\")\n",
    "    \n",
    "    # 为不同的模型类型创建正确的解释器\n",
    "    if is_xgb:\n",
    "        # XGBoost模型需要特殊处理\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        # 创建DMatrix格式的数据\n",
    "        X_shap_dmatrix = xgb.DMatrix(X_shap)\n",
    "        shap_values = explainer.shap_values(X_shap)\n",
    "    elif is_tree:\n",
    "        # 对于基于树的模型\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        shap_values = explainer.shap_values(X_shap)\n",
    "        # 处理CatBoost和LightGBM模型的特殊情况\n",
    "        if model_name == \"CatBoost\" or model_name == \"LightGBM\":\n",
    "            # 对于二分类模型，通常需要获取正类的SHAP值\n",
    "            if isinstance(shap_values, list) and len(shap_values) > 1:\n",
    "                shap_values = shap_values[1]  # 取正类的SHAP值\n",
    "    else:\n",
    "        # 对于其他类型的模型(如果有的话)\n",
    "        explainer = shap.KernelExplainer(model.predict_proba, X_shap.iloc[:100])  # 对于非树模型，样本量更小\n",
    "        shap_values = explainer.shap_values(X_shap.iloc[:100])\n",
    "        # 取正类的SHAP值\n",
    "        if isinstance(shap_values, list) and len(shap_values) > 1:\n",
    "            shap_values = shap_values[1]  # 取正类的SHAP值\n",
    "    \n",
    "    # 绘制摘要图 - 所有特征的全局重要性\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    shap.summary_plot(shap_values, X_shap, plot_type=\"bar\", show=False)\n",
    "    plt.title(f\"{model_name} - SHAP Feature Importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{model_shap_dir}/shap_importance.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # 绘制SHAP值的概述图\n",
    "    plt.figure(figsize=(14, 12))\n",
    "    shap.summary_plot(shap_values, X_shap, show=False)\n",
    "    plt.title(f\"{model_name} - SHAP Feature Impact Summary\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{model_shap_dir}/shap_summary.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # 为每个重要特征绘制详细的依赖图(最多前5个重要特征)\n",
    "    feature_importance = np.abs(shap_values).mean(0)\n",
    "    feature_names = X_shap.columns.tolist()\n",
    "    most_important_features_idx = np.argsort(-feature_importance)[:5]  # 取前5个最重要的特征\n",
    "    \n",
    "    for idx in most_important_features_idx:\n",
    "        feature_name = feature_names[idx]\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        shap.dependence_plot(idx, shap_values, X_shap, show=False)\n",
    "        plt.title(f\"{model_name} - SHAP Dependence Plot for '{feature_name}'\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{model_shap_dir}/shap_dependence_{feature_name}.png')\n",
    "        plt.close()\n",
    "        \n",
    "    print(f\"{model_name} 的SHAP分析完成，图表已保存到: {model_shap_dir}\")\n",
    "\n",
    "# 创建一个比较不同模型的SHAP特征重要性的函数，结果保存到全局比较目录\n",
    "def compare_shap_importance(models_to_analyze, X_shap):\n",
    "    \"\"\"比较不同模型的SHAP特征重要性\"\"\"\n",
    "    print(f\"\\n比较不同模型的SHAP特征重要性 - 保存到 {shap_dir}\")\n",
    "    \n",
    "    # 存储每个模型的特征重要性\n",
    "    model_importance = {}\n",
    "    \n",
    "    for model_info in models_to_analyze:\n",
    "        model_name = model_info[\"name\"]\n",
    "        model = model_info[\"model\"]\n",
    "        is_tree = model_info[\"is_tree\"]\n",
    "        is_xgb = model_info.get(\"is_xgb\", False)\n",
    "        \n",
    "        # 计算SHAP值\n",
    "        if is_xgb:\n",
    "            explainer = shap.TreeExplainer(model)\n",
    "            X_shap_dmatrix = xgb.DMatrix(X_shap)\n",
    "            shap_values = explainer.shap_values(X_shap)\n",
    "        elif is_tree:\n",
    "            explainer = shap.TreeExplainer(model)\n",
    "            shap_values = explainer.shap_values(X_shap)\n",
    "            if isinstance(shap_values, list) and len(shap_values) > 1:\n",
    "                shap_values = shap_values[1]  # 取正类的SHAP值\n",
    "        else:\n",
    "            # 其他类型的模型\n",
    "            explainer = shap.KernelExplainer(model.predict_proba, X_shap.iloc[:100])\n",
    "            shap_values = explainer.shap_values(X_shap.iloc[:100])\n",
    "            if isinstance(shap_values, list) and len(shap_values) > 1:\n",
    "                shap_values = shap_values[1]  # 取正类的SHAP值\n",
    "                \n",
    "        # 计算特征重要性\n",
    "        feature_importance = np.abs(shap_values).mean(0)\n",
    "        model_importance[model_name] = feature_importance\n",
    "    \n",
    "    # 创建DataFrame来比较所有模型的特征重要性\n",
    "    importance_df = pd.DataFrame(index=X_shap.columns)\n",
    "    \n",
    "    for model_name, importance in model_importance.items():\n",
    "        importance_df[model_name] = importance\n",
    "    \n",
    "    # 计算平均重要性并排序\n",
    "    importance_df['Mean_Importance'] = importance_df.mean(axis=1)\n",
    "    importance_df = importance_df.sort_values('Mean_Importance', ascending=False)\n",
    "    \n",
    "    # 保存特征重要性比较\n",
    "    importance_df.to_csv(f'{shap_dir}/shap_feature_importance_comparison.csv')\n",
    "    \n",
    "    # 选择前10个重要特征进行可视化\n",
    "    top_features = importance_df.head(10).index\n",
    "    plot_df = importance_df.loc[top_features].drop('Mean_Importance', axis=1)\n",
    "    \n",
    "    # 可视化不同模型的特征重要性比较\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    plot_df.plot(kind='bar', figsize=(14, 10))\n",
    "    plt.title('SHAP Feature Importance Comparison Across Models (Top 10 Features)')\n",
    "    plt.ylabel('SHAP Feature Importance (Mean |SHAP|)')\n",
    "    plt.xlabel('Features')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{shap_dir}/model_feature_importance_comparison.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return importance_df\n",
    "\n",
    "# 比较不同模型的SHAP特征重要性\n",
    "print(\"\\n比较不同模型的SHAP特征重要性...\")\n",
    "importance_comparison = compare_shap_importance(models_to_analyze, X_shap)\n",
    "print(\"特征重要性比较已完成并保存\")\n",
    "\n",
    "# 打印前10个最重要的特征\n",
    "print(\"\\n前10个最重要的特征 (基于平均SHAP重要性):\")\n",
    "print(importance_comparison[['Mean_Importance']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24dfd10",
   "metadata": {},
   "source": [
    "## 12. 动态权重集成模型\n",
    "\n",
    "在这个部分，我们将创建一个动态权重集成模型来整合前面训练的基础模型（CatBoost、LightGBM）的预测结果。与传统的固定权重集成不同，这里会基于每个数据点的特征为模型分配不同的权重，实现真正的动态权重分配。\n",
    "\n",
    "权重预测器将使用单独的训练数据集train_2.csv进行训练，并使用Optuna进行超参数调优，在验证集上进行早停。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "382cb3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 加载基础模型 =====\n",
      "\n",
      "加载CatBoost模型: /data/jinming/ee_stable/catboost/models/catboost_auc.cbm\n",
      "加载LightGBM模型: /data/jinming/ee_stable/lightgbm/models/lightgbm_auc.pkl\n",
      "\n",
      "===== 加载权重预测器的训练数据 =====\n",
      "\n",
      "train_2.csv数据集维度: (3000, 15)\n",
      "权重预测器训练数据维度: (3000, 13)\n",
      "特征数量: 13\n"
     ]
    }
   ],
   "source": [
    "# 1. 加载保存好的基础模型\n",
    "print(\"\\n===== 加载基础模型 =====\\n\")\n",
    "\n",
    "# 加载CatBoost模型\n",
    "catboost_model_path = f'{base_dir}/catboost/models/catboost_auc.cbm'\n",
    "loaded_catboost_model = cb.CatBoostClassifier()\n",
    "loaded_catboost_model.load_model(catboost_model_path)\n",
    "print(f\"加载CatBoost模型: {catboost_model_path}\")\n",
    "\n",
    "# 加载LightGBM模型\n",
    "lightgbm_model_path = f'{base_dir}/lightgbm/models/lightgbm_auc.pkl'\n",
    "loaded_lightgbm_model = joblib.load(lightgbm_model_path)\n",
    "print(f\"加载LightGBM模型: {lightgbm_model_path}\")\n",
    "\n",
    "# 2. 加载权重预测器的训练数据 - 使用train_2.csv\n",
    "print(\"\\n===== 加载权重预测器的训练数据 =====\\n\")\n",
    "train_2_df = pd.read_csv(f'{base_dir}/data/train_2.csv')\n",
    "print(f\"train_2.csv数据集维度: {train_2_df.shape}\")\n",
    "\n",
    "# 准备权重预测器的训练数据\n",
    "drop_columns = ['stab', 'stabf_encoded', 'stabf']\n",
    "X_train_2 = train_2_df.drop(drop_columns, axis=1)\n",
    "y_train_2 = train_2_df['stabf_encoded']\n",
    "\n",
    "# 对train_2数据应用特征工程\n",
    "X_train_2_featured, _, _ = create_features(X_train_2, X_test, X_val)\n",
    "\n",
    "# 应用特征选择（使用与之前相同的特征）\n",
    "X_train_2_final = X_train_2_featured[selected_features]\n",
    "\n",
    "print(f\"权重预测器训练数据维度: {X_train_2_final.shape}\")\n",
    "print(f\"特征数量: {X_train_2_final.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "792ec42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 生成基础模型的预测结果作为元特征 =====\n",
      "\n",
      "train_2数据集上的模型准确率：\n",
      "CatBoost: 0.9547\n",
      "LightGBM: 0.9523\n",
      "\n",
      "验证集上的模型准确率：\n",
      "CatBoost: 0.9640\n",
      "LightGBM: 0.9610\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3. 生成基础模型在各数据集上的预测结果作为元特征\n",
    "print(\"\\n===== 生成基础模型的预测结果作为元特征 =====\\n\")\n",
    "\n",
    "# 在train_2数据集上的预测概率（用于训练权重预测器）\n",
    "train_2_catboost_prob = loaded_catboost_model.predict_proba(X_train_2_final)[:, 1]\n",
    "train_2_lightgbm_prob = loaded_lightgbm_model.predict_proba(X_train_2_final)[:, 1]\n",
    "\n",
    "# 验证集上的预测概率\n",
    "val_catboost_prob = loaded_catboost_model.predict_proba(X_val_final)[:, 1]\n",
    "val_lightgbm_prob = loaded_lightgbm_model.predict_proba(X_val_final)[:, 1]\n",
    "\n",
    "# 测试集上的预测概率\n",
    "test_catboost_prob = loaded_catboost_model.predict_proba(X_test_final)[:, 1]\n",
    "test_lightgbm_prob = loaded_lightgbm_model.predict_proba(X_test_final)[:, 1]\n",
    "\n",
    "# 将预测概率转换为预测类别（0或1）\n",
    "train_2_catboost_pred = (train_2_catboost_prob > 0.5).astype(int)\n",
    "train_2_lightgbm_pred = (train_2_lightgbm_prob > 0.5).astype(int)\n",
    "\n",
    "val_catboost_pred = (val_catboost_prob > 0.5).astype(int)\n",
    "val_lightgbm_pred = (val_lightgbm_prob > 0.5).astype(int)\n",
    "\n",
    "# 计算每个基础模型在train_2上的预测是否正确（0表示错误，1表示正确）\n",
    "train_2_catboost_correct = (train_2_catboost_pred == y_train_2).astype(int)\n",
    "train_2_lightgbm_correct = (train_2_lightgbm_pred == y_train_2).astype(int)\n",
    "\n",
    "# 计算每个基础模型在验证集上的预测是否正确\n",
    "val_catboost_correct = (val_catboost_pred == y_val).astype(int)\n",
    "val_lightgbm_correct = (val_lightgbm_pred == y_val).astype(int)\n",
    "\n",
    "print(f\"train_2数据集上的模型准确率：\")\n",
    "print(f\"CatBoost: {train_2_catboost_correct.mean():.4f}\")\n",
    "print(f\"LightGBM: {train_2_lightgbm_correct.mean():.4f}\")\n",
    "\n",
    "print(f\"\\n验证集上的模型准确率：\")\n",
    "print(f\"CatBoost: {val_catboost_correct.mean():.4f}\")\n",
    "print(f\"LightGBM: {val_lightgbm_correct.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e91fe6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_2元特征数据框维度: (3000, 19)\n",
      "验证集元特征数据框维度: (1000, 19)\n",
      "元特征包括: ['tau1', 'tau2', 'tau3', 'tau4', 'g1', 'g2', 'g3', 'g4', 'tau1_g1', 'tau2_g2', 'tau3_g3', 'tau4_g4', 'tau_ratio', 'catboost_prob', 'lightgbm_prob', 'model_disagreement', 'prob_mean', 'prob_std', 'prob_range']\n"
     ]
    }
   ],
   "source": [
    "# 4. 创建元特征数据集 - 结合原始特征和模型预测\n",
    "\n",
    "# 为train_2数据创建元特征数据框（用于训练权重预测器）\n",
    "meta_features_train_2 = X_train_2_final.copy()\n",
    "\n",
    "# 添加两个模型的预测概率作为新的特征\n",
    "meta_features_train_2['catboost_prob'] = train_2_catboost_prob\n",
    "meta_features_train_2['lightgbm_prob'] = train_2_lightgbm_prob\n",
    "\n",
    "# 添加两个模型预测结果之间的不一致性作为特征\n",
    "meta_features_train_2['model_disagreement'] = (train_2_catboost_pred != train_2_lightgbm_pred).astype(int)\n",
    "\n",
    "# 添加预测概率的统计特征\n",
    "meta_features_train_2['prob_mean'] = (train_2_catboost_prob + train_2_lightgbm_prob) / 2\n",
    "meta_features_train_2['prob_std'] = np.std([train_2_catboost_prob, train_2_lightgbm_prob], axis=0)\n",
    "meta_features_train_2['prob_range'] = np.abs(train_2_catboost_prob - train_2_lightgbm_prob)\n",
    "\n",
    "# 为验证集创建元特征数据框（用于早停和评估）\n",
    "meta_features_val = X_val_final.copy()\n",
    "\n",
    "# 添加两个模型的预测概率作为新的特征\n",
    "meta_features_val['catboost_prob'] = val_catboost_prob\n",
    "meta_features_val['lightgbm_prob'] = val_lightgbm_prob\n",
    "\n",
    "# 添加两个模型预测结果之间的不一致性作为特征\n",
    "meta_features_val['model_disagreement'] = (val_catboost_pred != val_lightgbm_pred).astype(int)\n",
    "\n",
    "# 添加预测概率的统计特征\n",
    "meta_features_val['prob_mean'] = (val_catboost_prob + val_lightgbm_prob) / 2\n",
    "meta_features_val['prob_std'] = np.std([val_catboost_prob, val_lightgbm_prob], axis=0)\n",
    "meta_features_val['prob_range'] = np.abs(val_catboost_prob - val_lightgbm_prob)\n",
    "\n",
    "print(f\"train_2元特征数据框维度: {meta_features_train_2.shape}\")\n",
    "print(f\"验证集元特征数据框维度: {meta_features_val.shape}\")\n",
    "print(f\"元特征包括: {meta_features_train_2.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47222a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lightgbm权重预测器训练完成:\n",
      "训练集 - MSE: 0.0154, R²: 0.6606\n",
      "验证集 - MSE: 0.0277, R²: 0.2610\n",
      "保存lightgbm权重预测器到: /data/jinming/ee_stable/weight_models/lightgbm_weight_predictor.cbm\n",
      "\n",
      "所有权重预测器训练完成!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5. 定义和训练动态权重预测模型 - 使用Optuna调参\n",
    "\n",
    "print(\"\\n===== 使用Optuna调参训练动态权重预测模型 =====\\n\")\n",
    "\n",
    "# 创建权重预测模型的输出目录\n",
    "weight_models_dir = f'{base_dir}/weight_models'\n",
    "os.makedirs(weight_models_dir, exist_ok=True)\n",
    "\n",
    "# 根据train_2数据集上的表现分配基础模型的原始权重\n",
    "# (使用每个模型是否正确预测作为目标值)\n",
    "weight_targets = {\n",
    "    'catboost': train_2_catboost_correct,\n",
    "    'lightgbm': train_2_lightgbm_correct\n",
    "}\n",
    "\n",
    "# 创建权重预测模型\n",
    "weight_predictors = {}\n",
    "weight_studies = {}\n",
    "\n",
    "for model_name, target in weight_targets.items():\n",
    "    print(f\"\\n为{model_name}训练权重预测器...\")\n",
    "    \n",
    "    # 定义Optuna优化目标函数\n",
    "    def objective_weight_predictor(trial):\n",
    "        \"\"\"Optuna优化目标函数 - 使用验证集上的MSE作为评价指标\"\"\"\n",
    "        # 定义CatBoost参数搜索空间\n",
    "        params = {\n",
    "            'loss_function': 'RMSE',\n",
    "            'eval_metric': 'RMSE',\n",
    "            'verbose': False,\n",
    "            \n",
    "            # 核心参数\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "            'iterations': 1000,  # 使用早停\n",
    "            'depth': trial.suggest_int('depth', 4, 10),\n",
    "            \n",
    "            # 正则化参数\n",
    "            'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-8, 10.0, log=True),\n",
    "            'random_strength': trial.suggest_float('random_strength', 1e-8, 10.0, log=True),\n",
    "            'bagging_temperature': trial.suggest_float('bagging_temperature', 0, 10.0),\n",
    "            \n",
    "            # 其他参数\n",
    "            'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 100),\n",
    "            'leaf_estimation_iterations': trial.suggest_int('leaf_estimation_iterations', 1, 20),\n",
    "            'rsm': trial.suggest_float('rsm', 0.1, 1.0),  # 列采样比例\n",
    "            \n",
    "            # CPU特定参数\n",
    "            'task_type': 'CPU',\n",
    "            'thread_count': n_proc,\n",
    "            \n",
    "            'random_seed': 42\n",
    "        }\n",
    "        \n",
    "        # 创建CatBoost回归模型\n",
    "        model = cb.CatBoostRegressor(**params)\n",
    "        \n",
    "        # 在train_2上训练模型，使用验证集进行早停\n",
    "        model.fit(\n",
    "            meta_features_train_2, target,\n",
    "            eval_set=[(meta_features_val, weight_targets[model_name][:len(meta_features_val)])],\n",
    "            early_stopping_rounds=50,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        # 在验证集上预测\n",
    "        val_target = weight_targets[model_name][:len(meta_features_val)] if model_name == 'catboost' else val_lightgbm_correct\n",
    "        y_val_pred = model.predict(meta_features_val)\n",
    "        \n",
    "        # 计算MSE分数（越小越好，所以返回负值）\n",
    "        mse_score = np.mean((y_val_pred - val_target) ** 2)\n",
    "        \n",
    "        return -mse_score  # Optuna最大化目标，所以返回负MSE\n",
    "    \n",
    "    # 创建Optuna study对象\n",
    "    study_name = f'{model_name}_weight_predictor_optimization'\n",
    "    study = optuna.create_study(direction='maximize', study_name=study_name)\n",
    "    weight_studies[model_name] = study\n",
    "    \n",
    "    # 运行优化\n",
    "    print(f\"开始运行 {n_trials_optuna} 次调参试验...\")\n",
    "    start_time = time.time()\n",
    "    study.optimize(objective_weight_predictor, n_trials=n_trials_optuna)\n",
    "    end_time = time.time()\n",
    "    print(f\"调参完成! 耗时: {end_time - start_time:.2f}秒\")\n",
    "    \n",
    "    # 打印最佳参数和结果\n",
    "    print(f\"\\n{model_name}权重预测器最佳参数:\")\n",
    "    print(f\"最佳负MSE分数: {study.best_value:.4f}\")\n",
    "    print(\"最佳参数组合:\")\n",
    "    for key, value in study.best_params.items():\n",
    "        print(f\"    {key}: {value}\")\n",
    "    \n",
    "    # 使用最佳参数训练最终模型\n",
    "    best_params = study.best_params.copy()\n",
    "    best_params['loss_function'] = 'RMSE'\n",
    "    best_params['eval_metric'] = 'RMSE'\n",
    "    best_params['verbose'] = False\n",
    "    best_params['task_type'] = 'CPU'\n",
    "    best_params['thread_count'] = n_proc\n",
    "    best_params['random_seed'] = 42\n",
    "    \n",
    "    final_weight_model = cb.CatBoostRegressor(**best_params)\n",
    "    \n",
    "    # 训练权重预测模型\n",
    "    final_weight_model.fit(\n",
    "        meta_features_train_2, target,\n",
    "        eval_set=[(meta_features_val, val_catboost_correct if model_name == 'catboost' else val_lightgbm_correct)],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # 存储模型\n",
    "    weight_predictors[model_name] = final_weight_model\n",
    "    \n",
    "    # 计算训练精度\n",
    "    train_pred = final_weight_model.predict(meta_features_train_2)\n",
    "    train_mse = np.mean((train_pred - target) ** 2)\n",
    "    train_r2 = 1 - np.sum((train_pred - target) ** 2) / np.sum((target - np.mean(target)) ** 2)\n",
    "    \n",
    "    # 计算验证集精度\n",
    "    val_target = val_catboost_correct if model_name == 'catboost' else val_lightgbm_correct\n",
    "    val_pred = final_weight_model.predict(meta_features_val)\n",
    "    val_mse = np.mean((val_pred - val_target) ** 2)\n",
    "    val_r2 = 1 - np.sum((val_pred - val_target) ** 2) / np.sum((val_target - np.mean(val_target)) ** 2)\n",
    "    \n",
    "    print(f\"\\n{model_name}权重预测器训练完成:\")\n",
    "    print(f\"训练集 - MSE: {train_mse:.4f}, R²: {train_r2:.4f}\")\n",
    "    print(f\"验证集 - MSE: {val_mse:.4f}, R²: {val_r2:.4f}\")\n",
    "    \n",
    "    # 保存权重预测模型\n",
    "    weight_model_path = f'{weight_models_dir}/{model_name}_weight_predictor.cbm'\n",
    "    final_weight_model.save_model(weight_model_path)\n",
    "    print(f\"保存{model_name}权重预测器到: {weight_model_path}\")\n",
    "    \n",
    "    # 可视化调参过程\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    optuna.visualization.matplotlib.plot_optimization_history(study)\n",
    "    plt.title(f'{model_name.capitalize()} Weight Predictor Optimization History')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{weight_models_dir}/{model_name}_weight_predictor_optuna_history.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # 可视化超参数重要性\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    optuna.visualization.matplotlib.plot_param_importances(study)\n",
    "    plt.title(f'{model_name.capitalize()} Weight Predictor Parameter Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{weight_models_dir}/{model_name}_weight_predictor_param_importance.png')\n",
    "    plt.close()\n",
    "\n",
    "print(\"\\n所有权重预测器训练完成!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c29f92cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 为测试集创建元特征并预测权重 =====\n",
      "\n",
      "为测试集的每个样本预测动态权重...\n",
      "catboost的权重统计:\n",
      "  平均值: 0.9598\n",
      "  中位数: 0.9957\n",
      "  最小值: 0.2479\n",
      "  最大值: 1.0203\n",
      "  标准差: 0.0976\n",
      "lightgbm的权重统计:\n",
      "  平均值: 0.9608\n",
      "  中位数: 0.9921\n",
      "  最小值: 0.0454\n",
      "  最大值: 1.0741\n",
      "  标准差: 0.0958\n"
     ]
    }
   ],
   "source": [
    "# 6. 为测试集创建元特征并预测权重\n",
    "print(\"\\n===== 为测试集创建元特征并预测权重 =====\\n\")\n",
    "\n",
    "# 创建测试集的元特征\n",
    "meta_features_test = X_test_final.copy()\n",
    "\n",
    "# 添加两个模型的预测概率作为新特征\n",
    "meta_features_test['catboost_prob'] = test_catboost_prob\n",
    "meta_features_test['lightgbm_prob'] = test_lightgbm_prob\n",
    "\n",
    "# 添加两个模型预测结果之间的不一致性作为特征\n",
    "test_catboost_pred = (test_catboost_prob > 0.5).astype(int)\n",
    "test_lightgbm_pred = (test_lightgbm_prob > 0.5).astype(int)\n",
    "\n",
    "meta_features_test['model_disagreement'] = (test_catboost_pred != test_lightgbm_pred).astype(int)\n",
    "\n",
    "# 添加预测概率的统计特征\n",
    "meta_features_test['prob_mean'] = (test_catboost_prob + test_lightgbm_prob) / 2\n",
    "meta_features_test['prob_std'] = np.std([test_catboost_prob, test_lightgbm_prob], axis=0)\n",
    "meta_features_test['prob_range'] = np.abs(test_catboost_prob - test_lightgbm_prob)\n",
    "\n",
    "# 预测测试集的动态权重\n",
    "print(\"为测试集的每个样本预测动态权重...\")\n",
    "test_weights = {}\n",
    "\n",
    "for model_name, weight_model in weight_predictors.items():\n",
    "    # 预测权重（确保权重为正值）\n",
    "    weights = np.maximum(0, weight_model.predict(meta_features_test))\n",
    "    test_weights[model_name] = weights\n",
    "    print(f\"{model_name}的权重统计:\")\n",
    "    print(f\"  平均值: {weights.mean():.4f}\")\n",
    "    print(f\"  中位数: {np.median(weights):.4f}\")\n",
    "    print(f\"  最小值: {weights.min():.4f}\")\n",
    "    print(f\"  最大值: {weights.max():.4f}\")\n",
    "    print(f\"  标准差: {weights.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "498d2cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 生成动态权重集成预测并评估性能 =====\n",
      "\n",
      "动态权重集成模型在测试集上的性能:\n",
      "Accuracy: 0.9670\n",
      "AUC: 0.9963\n",
      "F1 Score: 0.9739\n",
      "Weighted F1 Score: 0.9669\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_comparison' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeighted F1 Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdynamic_ensemble_f1_weighted\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# 为比较添加动态集成模型的性能\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m test_comparison_with_ensemble \u001b[38;5;241m=\u001b[39m \u001b[43mtest_comparison\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     30\u001b[0m test_comparison_with_ensemble \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\n\u001b[1;32m     31\u001b[0m     test_comparison_with_ensemble,\n\u001b[1;32m     32\u001b[0m     pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m     })\n\u001b[1;32m     39\u001b[0m ], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# 保存更新的比较结果\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_comparison' is not defined"
     ]
    }
   ],
   "source": [
    "# 7. 使用动态权重生成最终预测并评估性能\n",
    "print(\"\\n===== 生成动态权重集成预测并评估性能 =====\\n\")\n",
    "\n",
    "# 组合预测结果 - 使用动态权重\n",
    "test_dynamic_ensemble_prob = (\n",
    "    test_weights['catboost'] * test_catboost_prob + \n",
    "    test_weights['lightgbm'] * test_lightgbm_prob\n",
    ") / (\n",
    "    test_weights['catboost'] + \n",
    "    test_weights['lightgbm'] + 1e-8  # 添加小的常数避免除零\n",
    ")\n",
    "\n",
    "# 转换为最终预测\n",
    "test_dynamic_ensemble_pred = (test_dynamic_ensemble_prob > 0.5).astype(int)\n",
    "\n",
    "# 计算动态权重集成的性能\n",
    "dynamic_ensemble_acc = accuracy_score(y_test, test_dynamic_ensemble_pred)\n",
    "dynamic_ensemble_auc = roc_auc_score(y_test, test_dynamic_ensemble_prob)\n",
    "dynamic_ensemble_f1 = f1_score(y_test, test_dynamic_ensemble_pred)\n",
    "dynamic_ensemble_f1_weighted = f1_score(y_test, test_dynamic_ensemble_pred, average='weighted')\n",
    "\n",
    "print(\"动态权重集成模型在测试集上的性能:\")\n",
    "print(f\"Accuracy: {dynamic_ensemble_acc:.4f}\")\n",
    "print(f\"AUC: {dynamic_ensemble_auc:.4f}\")\n",
    "print(f\"F1 Score: {dynamic_ensemble_f1:.4f}\")\n",
    "print(f\"Weighted F1 Score: {dynamic_ensemble_f1_weighted:.4f}\")\n",
    "\n",
    "# 为比较添加动态集成模型的性能\n",
    "test_comparison_with_ensemble = test_comparison.copy()\n",
    "test_comparison_with_ensemble = pd.concat([\n",
    "    test_comparison_with_ensemble,\n",
    "    pd.DataFrame({\n",
    "        'Model': ['Dynamic Ensemble (CB+LGBM)'],\n",
    "        'AUC': [dynamic_ensemble_auc],\n",
    "        'Accuracy': [dynamic_ensemble_acc],\n",
    "        'F1 Score': [dynamic_ensemble_f1],\n",
    "        'Weighted F1': [dynamic_ensemble_f1_weighted]\n",
    "    })\n",
    "], ignore_index=True)\n",
    "\n",
    "# 保存更新的比较结果\n",
    "test_comparison_with_ensemble.to_csv(f'{comparison_dir}/test_comparison_with_dynamic_ensemble.csv', index=False)\n",
    "\n",
    "print(\"\\n===== 所有模型性能比较 =====\\n\")\n",
    "print(test_comparison_with_ensemble)\n",
    "\n",
    "# 更新比较图表 - 测试集AUC比较\n",
    "plt.figure(figsize=(15, 8))\n",
    "colors = ['blue', 'green', 'orange', 'red']  # 为每个模型分配颜色\n",
    "bars = plt.bar(test_comparison_with_ensemble['Model'], test_comparison_with_ensemble['AUC'], color=colors)\n",
    "plt.title('Test Set - AUC Comparison with Dynamic Ensemble', fontsize=16)\n",
    "plt.ylabel('AUC Score', fontsize=14)\n",
    "plt.ylim(0.92, 1.0)  # 调整Y轴范围使差异更明显\n",
    "\n",
    "# 在每个柱子上显示数值\n",
    "for i, v in enumerate(test_comparison_with_ensemble['AUC']):\n",
    "    plt.text(i, v + 0.005, f\"{v:.4f}\", ha='center', fontsize=12)\n",
    "\n",
    "plt.xticks(rotation=15, fontsize=12)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{comparison_dir}/test_auc_comparison_with_dynamic_ensemble.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# 分析动态权重集成相对于其他模型的提升\n",
    "print(\"\\n===== 动态权重集成相对于基础模型的性能提升 =====\\n\")\n",
    "for idx, row in test_comparison.iterrows():\n",
    "    model_name = row['Model']\n",
    "    model_auc = row['AUC']\n",
    "    auc_improvement = dynamic_ensemble_auc - model_auc\n",
    "    acc_improvement = dynamic_ensemble_acc - row['Accuracy']\n",
    "    f1_improvement = dynamic_ensemble_f1 - row['F1 Score']\n",
    "    \n",
    "    print(f\"相对于{model_name}:\")\n",
    "    print(f\"  AUC提升: {auc_improvement:+.4f}\")\n",
    "    print(f\"  Accuracy提升: {acc_improvement:+.4f}\")\n",
    "    print(f\"  F1 Score提升: {f1_improvement:+.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b43d516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. 分析动态权重分布和特征重要性\n",
    "print(\"\\n===== 分析动态权重分布和特征重要性 =====\\n\")\n",
    "\n",
    "# 创建一个目录用于保存动态权重分析结果\n",
    "dynamic_weights_dir = f'{base_dir}/dynamic_weights_analysis'\n",
    "os.makedirs(dynamic_weights_dir, exist_ok=True)\n",
    "\n",
    "# 8.1 可视化两个模型的权重分布\n",
    "print(\"8.1 权重分布分析\")\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# 子图1: 权重分布直方图\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.histplot(test_weights['catboost'], kde=True, color='blue', alpha=0.6, label='CatBoost')\n",
    "sns.histplot(test_weights['lightgbm'], kde=True, color='green', alpha=0.6, label='LightGBM')\n",
    "plt.title('Distribution of Dynamic Weights for Each Model', fontsize=14)\n",
    "plt.xlabel('Weight Value', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 子图2: 权重散点图\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.scatter(test_weights['catboost'], test_weights['lightgbm'], alpha=0.6, s=20)\n",
    "plt.xlabel('CatBoost Weight', fontsize=12)\n",
    "plt.ylabel('LightGBM Weight', fontsize=12)\n",
    "plt.title('CatBoost vs LightGBM Weights', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 子图3: 权重相关性\n",
    "plt.subplot(2, 2, 3)\n",
    "weight_corr = np.corrcoef(test_weights['catboost'], test_weights['lightgbm'])[0, 1]\n",
    "plt.text(0.5, 0.6, f'Correlation: {weight_corr:.4f}', ha='center', va='center', \n",
    "         transform=plt.gca().transAxes, fontsize=16, \n",
    "         bbox=dict(boxstyle='round', facecolor='lightblue'))\n",
    "plt.text(0.5, 0.4, 'Weight Statistics:', ha='center', va='center', \n",
    "         transform=plt.gca().transAxes, fontsize=14, weight='bold')\n",
    "stats_text = f\"\"\"CatBoost: μ={test_weights['catboost'].mean():.3f}, σ={test_weights['catboost'].std():.3f}\n",
    "LightGBM: μ={test_weights['lightgbm'].mean():.3f}, σ={test_weights['lightgbm'].std():.3f}\"\"\"\n",
    "plt.text(0.5, 0.3, stats_text, ha='center', va='center', \n",
    "         transform=plt.gca().transAxes, fontsize=11)\n",
    "plt.title('Weight Statistics Summary', fontsize=14)\n",
    "plt.axis('off')\n",
    "\n",
    "# 子图4: 权重差异分布\n",
    "plt.subplot(2, 2, 4)\n",
    "weight_diff = test_weights['catboost'] - test_weights['lightgbm']\n",
    "sns.histplot(weight_diff, kde=True, color='purple', alpha=0.6)\n",
    "plt.title('Weight Difference Distribution\\n(CatBoost - LightGBM)', fontsize=14)\n",
    "plt.xlabel('Weight Difference', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.axvline(x=0, color='red', linestyle='--', alpha=0.7, label='Zero Difference')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{dynamic_weights_dir}/weight_distributions_analysis.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# 8.2 分析权重预测模型的特征重要性\n",
    "print(\"\\n8.2 权重预测器特征重要性分析\")\n",
    "\n",
    "for model_name, weight_model in weight_predictors.items():\n",
    "    print(f\"\\n分析{model_name}权重预测器:\")\n",
    "    \n",
    "    # 获取特征重要性\n",
    "    importance = weight_model.get_feature_importance()\n",
    "    feature_names = meta_features_train_2.columns\n",
    "    \n",
    "    # 按重要性排序\n",
    "    indices = np.argsort(importance)[::-1]\n",
    "    \n",
    "    # 创建特征重要性DataFrame\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': [feature_names[i] for i in indices],\n",
    "        'Importance': importance[indices]\n",
    "    })\n",
    "    \n",
    "    # 保存特征重要性结果\n",
    "    importance_df.to_csv(f'{dynamic_weights_dir}/{model_name}_weight_predictor_feature_importance.csv', index=False)\n",
    "    \n",
    "    # 可视化特征重要性\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    top_features = min(15, len(importance))  # 显示前15个最重要的特征\n",
    "    \n",
    "    sns.barplot(x='Importance', y='Feature', data=importance_df.head(top_features))\n",
    "    plt.title(f'{model_name.capitalize()} Weight Predictor - Top {top_features} Feature Importance', fontsize=16)\n",
    "    plt.xlabel('Feature Importance', fontsize=14)\n",
    "    plt.ylabel('Features', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{dynamic_weights_dir}/{model_name}_weight_predictor_feature_importance.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # 打印最重要的10个特征\n",
    "    print(f\"Top 10最重要的特征:\")\n",
    "    for i in range(min(10, len(indices))):\n",
    "        print(f\"  {i+1}. {feature_names[indices[i]]}: {importance[indices[i]]:.4f}\")\n",
    "\n",
    "# 8.3 分析预测的权重与模型性能的关系\n",
    "print(\"\\n8.3 权重与模型性能关系分析\")\n",
    "\n",
    "test_catboost_correct = (test_catboost_pred == y_test).astype(int)\n",
    "test_lightgbm_correct = (test_lightgbm_pred == y_test).astype(int)\n",
    "\n",
    "# 创建一个数据框用于分析\n",
    "weight_performance_df = pd.DataFrame({\n",
    "    'Catboost_Weight': test_weights['catboost'],\n",
    "    'Lightgbm_Weight': test_weights['lightgbm'],\n",
    "    'Catboost_Correct': test_catboost_correct,\n",
    "    'Lightgbm_Correct': test_lightgbm_correct,\n",
    "    'Ensemble_Correct': (test_dynamic_ensemble_pred == y_test).astype(int)\n",
    "})\n",
    "\n",
    "# 计算每个模型权重与其预测正确性的相关性\n",
    "print(\"权重与模型预测正确性的相关性:\")\n",
    "for model in ['catboost', 'lightgbm']:\n",
    "    corr = np.corrcoef(weight_performance_df[f'{model.capitalize()}_Weight'], \n",
    "                      weight_performance_df[f'{model.capitalize()}_Correct'])[0, 1]\n",
    "    print(f\"  {model.capitalize()}权重与预测正确性相关性: {corr:.4f}\")\n",
    "\n",
    "# 可视化权重与预测正确性的关系\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 为每个模型创建权重分布对比图\n",
    "for i, model in enumerate(['catboost', 'lightgbm']):\n",
    "    # 子图1: 权重分布按预测正确性分组\n",
    "    ax1 = axes[i, 0]\n",
    "    correct_weights = weight_performance_df[weight_performance_df[f'{model.capitalize()}_Correct'] == 1][f'{model.capitalize()}_Weight']\n",
    "    incorrect_weights = weight_performance_df[weight_performance_df[f'{model.capitalize()}_Correct'] == 0][f'{model.capitalize()}_Weight']\n",
    "    \n",
    "    sns.kdeplot(correct_weights, label='Correct Predictions', color='green', shade=True, ax=ax1)\n",
    "    sns.kdeplot(incorrect_weights, label='Incorrect Predictions', color='red', shade=True, ax=ax1)\n",
    "    \n",
    "    ax1.set_title(f'{model.capitalize()} Weight Distribution by Prediction Correctness')\n",
    "    ax1.set_xlabel('Weight Value')\n",
    "    ax1.set_ylabel('Density')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 子图2: 权重箱线图\n",
    "    ax2 = axes[i, 1]\n",
    "    box_data = [correct_weights, incorrect_weights]\n",
    "    bp = ax2.boxplot(box_data, labels=['Correct', 'Incorrect'], patch_artist=True)\n",
    "    bp['boxes'][0].set_facecolor('green')\n",
    "    bp['boxes'][0].set_alpha(0.6)\n",
    "    bp['boxes'][1].set_facecolor('red')\n",
    "    bp['boxes'][1].set_alpha(0.6)\n",
    "    \n",
    "    ax2.set_title(f'{model.capitalize()} Weight Distribution (Box Plot)')\n",
    "    ax2.set_ylabel('Weight Value')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{dynamic_weights_dir}/weight_vs_prediction_correctness.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# 8.4 权重选择效果分析\n",
    "print(\"\\n8.4 权重选择效果分析\")\n",
    "\n",
    "# 分析在不同情况下权重分配的合理性\n",
    "# 1. 当两个模型都正确时\n",
    "both_correct = (test_catboost_correct == 1) & (test_lightgbm_correct == 1)\n",
    "# 2. 当只有CatBoost正确时\n",
    "only_catboost_correct = (test_catboost_correct == 1) & (test_lightgbm_correct == 0)\n",
    "# 3. 当只有LightGBM正确时\n",
    "only_lightgbm_correct = (test_catboost_correct == 0) & (test_lightgbm_correct == 1)\n",
    "# 4. 当两个模型都错误时\n",
    "both_incorrect = (test_catboost_correct == 0) & (test_lightgbm_correct == 0)\n",
    "\n",
    "scenarios = {\n",
    "    'Both Correct': both_correct,\n",
    "    'Only CatBoost Correct': only_catboost_correct,\n",
    "    'Only LightGBM Correct': only_lightgbm_correct,\n",
    "    'Both Incorrect': both_incorrect\n",
    "}\n",
    "\n",
    "print(\"不同预测场景下的权重分配统计:\")\n",
    "scenario_stats = []\n",
    "\n",
    "for scenario_name, mask in scenarios.items():\n",
    "    if mask.sum() > 0:  # 确保该场景有样本\n",
    "        cb_weight_mean = test_weights['catboost'][mask].mean()\n",
    "        lgb_weight_mean = test_weights['lightgbm'][mask].mean()\n",
    "        count = mask.sum()\n",
    "        \n",
    "        scenario_stats.append({\n",
    "            'Scenario': scenario_name,\n",
    "            'Count': count,\n",
    "            'CatBoost_Weight_Mean': cb_weight_mean,\n",
    "            'LightGBM_Weight_Mean': lgb_weight_mean,\n",
    "            'Weight_Ratio_CB/LGB': cb_weight_mean / (lgb_weight_mean + 1e-8)\n",
    "        })\n",
    "        \n",
    "        print(f\"\\n{scenario_name} ({count} samples):\")\n",
    "        print(f\"  CatBoost平均权重: {cb_weight_mean:.4f}\")\n",
    "        print(f\"  LightGBM平均权重: {lgb_weight_mean:.4f}\")\n",
    "        print(f\"  权重比例 (CB/LGB): {cb_weight_mean / (lgb_weight_mean + 1e-8):.4f}\")\n",
    "\n",
    "# 保存场景统计\n",
    "scenario_stats_df = pd.DataFrame(scenario_stats)\n",
    "scenario_stats_df.to_csv(f'{dynamic_weights_dir}/weight_allocation_by_scenario.csv', index=False)\n",
    "\n",
    "print(f\"\\n动态权重分析完成，所有结果保存到: {dynamic_weights_dir}\")\n",
    "print(\"\\n===== 动态权重集成模型训练和分析完成! =====\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb0315d",
   "metadata": {},
   "source": [
    "备选: 使用Weighted F1作为优化目标的模型训练\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "# CatBoost - Weighted F1优化\n",
    "def objective_catboost_wf1(trial):\n",
    "    # 定义CatBoost参数搜索空间\n",
    "    params = {\n",
    "        'loss_function': 'Logloss',\n",
    "        'eval_metric': 'Logloss',\n",
    "        'verbose': 0,\n",
    "        \n",
    "        # 核心参数\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.5, log=True),\n",
    "        'iterations': 2000,\n",
    "        'depth': trial.suggest_int('depth', 3, 10),\n",
    "        \n",
    "        # 正则化参数\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-8, 10.0, log=True),\n",
    "        'random_strength': trial.suggest_float('random_strength', 1e-8, 10.0, log=True),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0, 10.0),\n",
    "        \n",
    "        # 其他参数\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 100),\n",
    "        'rsm': trial.suggest_float('rsm', 0.1, 1.0),\n",
    "        \n",
    "        'thread_count': 16,\n",
    "        'random_seed': 42\n",
    "    }\n",
    "    \n",
    "    # 创建CatBoost模型\n",
    "    model = cb.CatBoostClassifier(**params)\n",
    "    \n",
    "    # 训练模型\n",
    "    model.fit(\n",
    "        X_train_final, y_train,\n",
    "        eval_set=[(X_val_final, y_val)],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # 在验证集上预测\n",
    "    y_val_pred = model.predict(X_val_final)\n",
    "    \n",
    "    # 计算weighted F1分数\n",
    "    f1_weighted = f1_score(y_val, y_val_pred, average='weighted')\n",
    "    \n",
    "    print(f\"Trial {trial.number}: Weighted F1 = {f1_weighted:.4f}\")\n",
    "    \n",
    "    return f1_weighted\n",
    "\n",
    "# LightGBM - Weighted F1优化\n",
    "def objective_lightgbm_wf1(trial):\n",
    "    # 定义LightGBM参数搜索空间\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'verbosity': -1,\n",
    "        \n",
    "        # 核心参数\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.5, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 30, 1000),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 10, 150),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "        \n",
    "        # 正则化参数\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "        \n",
    "        # 其他参数\n",
    "        'min_split_gain': trial.suggest_float('min_split_gain', 0, 0.5),\n",
    "        'min_child_weight': trial.suggest_float('min_child_weight', 1e-5, 10.0, log=True),\n",
    "        \n",
    "        'n_jobs': 16,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    # 创建LightGBM模型\n",
    "    model = lgb.LGBMClassifier(**params)\n",
    "    \n",
    "    # 训练模型\n",
    "    model.fit(\n",
    "        X_train_final, y_train,\n",
    "        eval_set=[(X_val_final, y_val)],\n",
    "        eval_metric='logloss',\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)]\n",
    "    )\n",
    "    \n",
    "    # 在验证集上预测\n",
    "    y_val_pred = model.predict(X_val_final)\n",
    "    \n",
    "    # 计算weighted F1分数\n",
    "    f1_weighted = f1_score(y_val, y_val_pred, average='weighted')\n",
    "    \n",
    "    print(f\"Trial {trial.number}: Weighted F1 = {f1_weighted:.4f}\")\n",
    "    \n",
    "    return f1_weighted\n",
    "\n",
    "# XGBoost - Weighted F1优化\n",
    "def objective_xgboost_wf1(trial):\n",
    "    # 定义XGBoost参数搜索空间\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'verbosity': 0,\n",
    "        \n",
    "        # 核心参数\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.5, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        \n",
    "        # 正则化参数\n",
    "        'min_child_weight': trial.suggest_float('min_child_weight', 1, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 10),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-8, 10.0, log=True),\n",
    "        'lambda': trial.suggest_float('lambda', 1e-8, 10.0, log=True),\n",
    "        \n",
    "        # CPU特定参数\n",
    "        'tree_method': 'hist',\n",
    "        'n_jobs': 16,\n",
    "        \n",
    "        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 0.1, 10.0),\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train_final, label=y_train)\n",
    "    dval = xgb.DMatrix(X_val_final, label=y_val)\n",
    "    \n",
    "    evals = [(dtrain, 'train'), (dval, 'val')]\n",
    "    evals_result = {}\n",
    "    \n",
    "    model = xgb.train(\n",
    "        params=params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=2000,\n",
    "        evals=evals,\n",
    "        early_stopping_rounds=50,\n",
    "        evals_result=evals_result,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "    \n",
    "    y_val_prob = model.predict(dval)\n",
    "    y_val_pred = (y_val_prob > 0.5).astype(int)\n",
    "    \n",
    "    f1_weighted = f1_score(y_val, y_val_pred, average='weighted')\n",
    "    \n",
    "    print(f\"Trial {trial.number}: Weighted F1 = {f1_weighted:.4f}\")\n",
    "    \n",
    "    return f1_weighted\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
